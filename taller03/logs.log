2025-06-07 21:59:00,759:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-07 21:59:00,759:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-07 21:59:00,759:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-07 21:59:00,760:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-07 21:59:07,886:INFO:PyCaret ClassificationExperiment
2025-06-07 21:59:07,886:INFO:Logging name: respuesta-autoML
2025-06-07 21:59:07,886:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-06-07 21:59:07,887:INFO:version 3.3.2
2025-06-07 21:59:07,887:INFO:Initializing setup()
2025-06-07 21:59:07,887:INFO:self.USI: 61e5
2025-06-07 21:59:07,887:INFO:self._variable_keys: {'is_multiclass', 'y', 'fold_shuffle_param', 'fold_generator', 'target_param', '_available_plots', 'fix_imbalance', 'X', 'n_jobs_param', 'y_test', 'fold_groups_param', 'USI', 'log_plots_param', 'X_train', 'X_test', 'gpu_param', 'html_param', 'data', 'exp_id', 'exp_name_log', 'gpu_n_jobs_param', 'idx', 'logging_param', 'pipeline', 'y_train', '_ml_usecase', 'memory', 'seed'}
2025-06-07 21:59:07,887:INFO:Checking environment
2025-06-07 21:59:07,887:INFO:python_version: 3.11.0
2025-06-07 21:59:07,887:INFO:python_build: ('main', 'Oct 24 2022 18:26:48')
2025-06-07 21:59:07,887:INFO:machine: AMD64
2025-06-07 21:59:07,912:INFO:platform: Windows-10-10.0.26100-SP0
2025-06-07 21:59:07,934:INFO:Memory: svmem(total=16438312960, available=859803648, percent=94.8, used=15578509312, free=859803648)
2025-06-07 21:59:07,934:INFO:Physical Core: 8
2025-06-07 21:59:07,934:INFO:Logical Core: 16
2025-06-07 21:59:07,934:INFO:Checking libraries
2025-06-07 21:59:07,934:INFO:System:
2025-06-07 21:59:07,934:INFO:    python: 3.11.0 (main, Oct 24 2022, 18:26:48) [MSC v.1933 64 bit (AMD64)]
2025-06-07 21:59:07,934:INFO:executable: C:\env\ml\Scripts\python.exe
2025-06-07 21:59:07,934:INFO:   machine: Windows-10-10.0.26100-SP0
2025-06-07 21:59:07,934:INFO:PyCaret required dependencies:
2025-06-07 21:59:08,233:INFO:                 pip: 22.3
2025-06-07 21:59:08,233:INFO:          setuptools: 65.5.0
2025-06-07 21:59:08,233:INFO:             pycaret: 3.3.2
2025-06-07 21:59:08,233:INFO:             IPython: 9.2.0
2025-06-07 21:59:08,233:INFO:          ipywidgets: 8.1.7
2025-06-07 21:59:08,233:INFO:                tqdm: 4.67.1
2025-06-07 21:59:08,233:INFO:               numpy: 1.26.4
2025-06-07 21:59:08,233:INFO:              pandas: 2.1.4
2025-06-07 21:59:08,233:INFO:              jinja2: 3.1.6
2025-06-07 21:59:08,233:INFO:               scipy: 1.11.4
2025-06-07 21:59:08,233:INFO:              joblib: 1.3.2
2025-06-07 21:59:08,233:INFO:             sklearn: 1.4.2
2025-06-07 21:59:08,233:INFO:                pyod: 2.0.5
2025-06-07 21:59:08,233:INFO:            imblearn: 0.13.0
2025-06-07 21:59:08,233:INFO:   category_encoders: 2.7.0
2025-06-07 21:59:08,233:INFO:            lightgbm: 4.6.0
2025-06-07 21:59:08,233:INFO:               numba: 0.61.0
2025-06-07 21:59:08,233:INFO:            requests: 2.32.3
2025-06-07 21:59:08,233:INFO:          matplotlib: 3.7.5
2025-06-07 21:59:08,233:INFO:          scikitplot: 0.3.7
2025-06-07 21:59:08,233:INFO:         yellowbrick: 1.5
2025-06-07 21:59:08,234:INFO:              plotly: 5.24.1
2025-06-07 21:59:08,234:INFO:    plotly-resampler: Not installed
2025-06-07 21:59:08,234:INFO:             kaleido: 0.2.1
2025-06-07 21:59:08,234:INFO:           schemdraw: 0.15
2025-06-07 21:59:08,234:INFO:         statsmodels: 0.14.4
2025-06-07 21:59:08,234:INFO:              sktime: 0.26.0
2025-06-07 21:59:08,234:INFO:               tbats: 1.1.3
2025-06-07 21:59:08,234:INFO:            pmdarima: 2.0.4
2025-06-07 21:59:08,234:INFO:              psutil: 7.0.0
2025-06-07 21:59:08,234:INFO:          markupsafe: 3.0.2
2025-06-07 21:59:08,234:INFO:             pickle5: Not installed
2025-06-07 21:59:08,234:INFO:         cloudpickle: 3.1.1
2025-06-07 21:59:08,234:INFO:         deprecation: 2.1.0
2025-06-07 21:59:08,234:INFO:              xxhash: 3.5.0
2025-06-07 21:59:08,234:INFO:           wurlitzer: Not installed
2025-06-07 21:59:08,234:INFO:PyCaret optional dependencies:
2025-06-07 21:59:08,715:INFO:                shap: 0.44.1
2025-06-07 21:59:08,715:INFO:           interpret: 0.6.10
2025-06-07 21:59:08,715:INFO:                umap: 0.5.7
2025-06-07 21:59:08,715:INFO:     ydata_profiling: 4.16.1
2025-06-07 21:59:08,716:INFO:  explainerdashboard: 0.4.8
2025-06-07 21:59:08,716:INFO:             autoviz: Not installed
2025-06-07 21:59:08,716:INFO:           fairlearn: 0.7.0
2025-06-07 21:59:08,716:INFO:          deepchecks: Not installed
2025-06-07 21:59:08,716:INFO:             xgboost: Not installed
2025-06-07 21:59:08,716:INFO:            catboost: Not installed
2025-06-07 21:59:08,716:INFO:              kmodes: Not installed
2025-06-07 21:59:08,716:INFO:             mlxtend: Not installed
2025-06-07 21:59:08,716:INFO:       statsforecast: Not installed
2025-06-07 21:59:08,716:INFO:        tune_sklearn: Not installed
2025-06-07 21:59:08,716:INFO:                 ray: Not installed
2025-06-07 21:59:08,716:INFO:            hyperopt: Not installed
2025-06-07 21:59:08,716:INFO:              optuna: Not installed
2025-06-07 21:59:08,716:INFO:               skopt: Not installed
2025-06-07 21:59:08,716:INFO:              mlflow: 2.22.0
2025-06-07 21:59:08,716:INFO:              gradio: Not installed
2025-06-07 21:59:08,716:INFO:             fastapi: 0.115.12
2025-06-07 21:59:08,716:INFO:             uvicorn: 0.34.2
2025-06-07 21:59:08,716:INFO:              m2cgen: Not installed
2025-06-07 21:59:08,716:INFO:           evidently: Not installed
2025-06-07 21:59:08,716:INFO:               fugue: Not installed
2025-06-07 21:59:08,716:INFO:           streamlit: Not installed
2025-06-07 21:59:08,716:INFO:             prophet: Not installed
2025-06-07 21:59:08,716:INFO:None
2025-06-07 21:59:08,716:INFO:Set up data.
2025-06-07 21:59:08,728:INFO:Set up folding strategy.
2025-06-07 21:59:08,728:INFO:Set up train/test split.
2025-06-07 21:59:08,764:INFO:Set up index.
2025-06-07 21:59:08,765:INFO:Assigning column types.
2025-06-07 21:59:08,767:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-06-07 21:59:08,795:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-07 21:59:08,801:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-06-07 21:59:08,916:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-07 21:59:08,917:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-07 21:59:08,945:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-07 21:59:08,946:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-06-07 21:59:08,964:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-07 21:59:08,964:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-07 21:59:08,965:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-06-07 21:59:08,994:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-06-07 21:59:09,011:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-07 21:59:09,011:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-07 21:59:09,040:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-06-07 21:59:09,058:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-07 21:59:09,058:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-07 21:59:09,058:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-06-07 21:59:09,104:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-07 21:59:09,104:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-07 21:59:09,149:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-07 21:59:09,150:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-07 21:59:09,151:INFO:Preparing preprocessing pipeline...
2025-06-07 21:59:09,153:INFO:Set up simple imputation.
2025-06-07 21:59:09,156:INFO:Set up encoding of ordinal features.
2025-06-07 21:59:09,157:INFO:Set up encoding of categorical features.
2025-06-07 21:59:09,210:INFO:Finished creating preprocessing pipeline.
2025-06-07 21:59:09,274:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\JOSECA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'ingreso_mensual',
                                             'usa_app', 'usa_web',
                                             'satisfaccion', 'num_productos',
                                             'reclamos_ult_6m',
                                             'tasa_credito'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_feature...
                                                                         'data_type': dtype('O'),
                                                                         'mapping': F      0
M      1
NaN   -1
dtype: int64}],
                                                               return_df=True,
                                                               verbose=0))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['nivel_educacion', 'region'],
                                    transformer=OneHotEncoder(cols=['nivel_educacion',
                                                                    'region'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2025-06-07 21:59:09,274:INFO:Creating final display dataframe.
2025-06-07 21:59:09,405:INFO:Setup _display_container:                     Description             Value
0                    Session id               131
1                        Target  respondio_oferta
2                   Target type            Binary
3           Original data shape         (500, 13)
4        Transformed data shape         (500, 18)
5   Transformed train set shape         (350, 18)
6    Transformed test set shape         (150, 18)
7               Ignore features                 1
8              Numeric features                 8
9          Categorical features                 3
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator   StratifiedKFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment      MlflowLogger
21              Experiment Name  respuesta-autoML
22                          USI              61e5
2025-06-07 21:59:09,468:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-07 21:59:09,468:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-07 21:59:09,516:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-07 21:59:09,516:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-07 21:59:09,517:INFO:Logging experiment in loggers
2025-06-07 21:59:10,138:INFO:SubProcess save_model() called ==================================
2025-06-07 21:59:10,160:INFO:Initializing save_model()
2025-06-07 21:59:10,160:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\JOSECA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'ingreso_mensual',
                                             'usa_app', 'usa_web',
                                             'satisfaccion', 'num_productos',
                                             'reclamos_ult_6m',
                                             'tasa_credito'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_feature...
                                                                         'data_type': dtype('O'),
                                                                         'mapping': F      0
M      1
NaN   -1
dtype: int64}],
                                                               return_df=True,
                                                               verbose=0))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['nivel_educacion', 'region'],
                                    transformer=OneHotEncoder(cols=['nivel_educacion',
                                                                    'region'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False), model_name=C:\Users\JOSECA~1\AppData\Local\Temp\tmpbqc7l2l7\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\JOSECA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'ingreso_mensual',
                                             'usa_app', 'usa_web',
                                             'satisfaccion', 'num_productos',
                                             'reclamos_ult_6m',
                                             'tasa_credito'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_feature...
                                                                         'data_type': dtype('O'),
                                                                         'mapping': F      0
M      1
NaN   -1
dtype: int64}],
                                                               return_df=True,
                                                               verbose=0))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['nivel_educacion', 'region'],
                                    transformer=OneHotEncoder(cols=['nivel_educacion',
                                                                    'region'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False), verbose=False, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-06-07 21:59:10,160:INFO:Adding model into prep_pipe
2025-06-07 21:59:10,160:WARNING:Only Model saved as it was a pipeline.
2025-06-07 21:59:10,173:INFO:C:\Users\JOSECA~1\AppData\Local\Temp\tmpbqc7l2l7\Transformation Pipeline.pkl saved in current working directory
2025-06-07 21:59:10,185:INFO:Pipeline(memory=FastMemory(location=C:\Users\JOSECA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'ingreso_mensual',
                                             'usa_app', 'usa_web',
                                             'satisfaccion', 'num_productos',
                                             'reclamos_ult_6m',
                                             'tasa_credito'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_feature...
                                                                         'data_type': dtype('O'),
                                                                         'mapping': F      0
M      1
NaN   -1
dtype: int64}],
                                                               return_df=True,
                                                               verbose=0))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['nivel_educacion', 'region'],
                                    transformer=OneHotEncoder(cols=['nivel_educacion',
                                                                    'region'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2025-06-07 21:59:10,185:INFO:save_model() successfully completed......................................
2025-06-07 21:59:10,276:INFO:SubProcess save_model() end ==================================
2025-06-07 21:59:10,292:INFO:setup() successfully completed in 1.65s...............
2025-06-07 21:59:10,292:INFO:Initializing compare_models()
2025-06-07 21:59:10,292:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002099F6B5D10>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002099F6B5D10>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-06-07 21:59:10,292:INFO:Checking exceptions
2025-06-07 21:59:10,295:INFO:Preparing display monitor
2025-06-07 21:59:10,298:INFO:Initializing Logistic Regression
2025-06-07 21:59:10,298:INFO:Total runtime is 0.0 minutes
2025-06-07 21:59:10,298:INFO:SubProcess create_model() called ==================================
2025-06-07 21:59:10,298:INFO:Initializing create_model()
2025-06-07 21:59:10,298:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002099F6B5D10>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209EAB81950>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-07 21:59:10,298:INFO:Checking exceptions
2025-06-07 21:59:10,299:INFO:Importing libraries
2025-06-07 21:59:10,299:INFO:Copying training dataset
2025-06-07 21:59:10,301:INFO:Defining folds
2025-06-07 21:59:10,301:INFO:Declaring metric variables
2025-06-07 21:59:10,301:INFO:Importing untrained model
2025-06-07 21:59:10,301:INFO:Logistic Regression Imported successfully
2025-06-07 21:59:10,301:INFO:Starting cross validation
2025-06-07 21:59:10,302:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-07 21:59:16,178:WARNING:C:\env\ml\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-07 21:59:16,183:WARNING:C:\env\ml\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-07 21:59:16,195:WARNING:C:\env\ml\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-07 21:59:16,196:WARNING:C:\env\ml\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-07 21:59:16,199:WARNING:C:\env\ml\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-07 21:59:16,215:WARNING:C:\env\ml\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-07 21:59:16,215:WARNING:C:\env\ml\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-07 21:59:16,222:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 21:59:16,224:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 21:59:16,228:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 21:59:16,231:WARNING:C:\env\ml\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-07 21:59:16,232:WARNING:C:\env\ml\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-07 21:59:16,256:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 21:59:16,283:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 21:59:16,294:INFO:Calculating mean and std
2025-06-07 21:59:16,297:INFO:Creating metrics dataframe
2025-06-07 21:59:16,301:INFO:Uploading results into container
2025-06-07 21:59:16,303:INFO:Uploading model into container now
2025-06-07 21:59:16,303:INFO:_master_model_container: 1
2025-06-07 21:59:16,304:INFO:_display_container: 2
2025-06-07 21:59:16,304:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=131, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-06-07 21:59:16,304:INFO:create_model() successfully completed......................................
2025-06-07 21:59:16,434:INFO:SubProcess create_model() end ==================================
2025-06-07 21:59:16,434:INFO:Creating metrics dataframe
2025-06-07 21:59:16,435:INFO:Initializing K Neighbors Classifier
2025-06-07 21:59:16,436:INFO:Total runtime is 0.10229748884836833 minutes
2025-06-07 21:59:16,436:INFO:SubProcess create_model() called ==================================
2025-06-07 21:59:16,436:INFO:Initializing create_model()
2025-06-07 21:59:16,436:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002099F6B5D10>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209EAB81950>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-07 21:59:16,436:INFO:Checking exceptions
2025-06-07 21:59:16,436:INFO:Importing libraries
2025-06-07 21:59:16,436:INFO:Copying training dataset
2025-06-07 21:59:16,439:INFO:Defining folds
2025-06-07 21:59:16,439:INFO:Declaring metric variables
2025-06-07 21:59:16,439:INFO:Importing untrained model
2025-06-07 21:59:16,439:INFO:K Neighbors Classifier Imported successfully
2025-06-07 21:59:16,439:INFO:Starting cross validation
2025-06-07 21:59:16,440:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-07 21:59:22,555:INFO:Calculating mean and std
2025-06-07 21:59:22,557:INFO:Creating metrics dataframe
2025-06-07 21:59:22,560:INFO:Uploading results into container
2025-06-07 21:59:22,562:INFO:Uploading model into container now
2025-06-07 21:59:22,563:INFO:_master_model_container: 2
2025-06-07 21:59:22,563:INFO:_display_container: 2
2025-06-07 21:59:22,563:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-06-07 21:59:22,564:INFO:create_model() successfully completed......................................
2025-06-07 21:59:22,690:INFO:SubProcess create_model() end ==================================
2025-06-07 21:59:22,690:INFO:Creating metrics dataframe
2025-06-07 21:59:22,692:INFO:Initializing Naive Bayes
2025-06-07 21:59:22,692:INFO:Total runtime is 0.20656546354293823 minutes
2025-06-07 21:59:22,692:INFO:SubProcess create_model() called ==================================
2025-06-07 21:59:22,693:INFO:Initializing create_model()
2025-06-07 21:59:22,693:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002099F6B5D10>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209EAB81950>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-07 21:59:22,693:INFO:Checking exceptions
2025-06-07 21:59:22,693:INFO:Importing libraries
2025-06-07 21:59:22,693:INFO:Copying training dataset
2025-06-07 21:59:22,696:INFO:Defining folds
2025-06-07 21:59:22,696:INFO:Declaring metric variables
2025-06-07 21:59:22,696:INFO:Importing untrained model
2025-06-07 21:59:22,696:INFO:Naive Bayes Imported successfully
2025-06-07 21:59:22,697:INFO:Starting cross validation
2025-06-07 21:59:22,697:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-07 21:59:22,821:INFO:Calculating mean and std
2025-06-07 21:59:22,822:INFO:Creating metrics dataframe
2025-06-07 21:59:22,824:INFO:Uploading results into container
2025-06-07 21:59:22,824:INFO:Uploading model into container now
2025-06-07 21:59:22,824:INFO:_master_model_container: 3
2025-06-07 21:59:22,824:INFO:_display_container: 2
2025-06-07 21:59:22,825:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-06-07 21:59:22,825:INFO:create_model() successfully completed......................................
2025-06-07 21:59:22,918:INFO:SubProcess create_model() end ==================================
2025-06-07 21:59:22,918:INFO:Creating metrics dataframe
2025-06-07 21:59:22,920:INFO:Initializing Decision Tree Classifier
2025-06-07 21:59:22,920:INFO:Total runtime is 0.21037506262461345 minutes
2025-06-07 21:59:22,920:INFO:SubProcess create_model() called ==================================
2025-06-07 21:59:22,920:INFO:Initializing create_model()
2025-06-07 21:59:22,920:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002099F6B5D10>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209EAB81950>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-07 21:59:22,920:INFO:Checking exceptions
2025-06-07 21:59:22,920:INFO:Importing libraries
2025-06-07 21:59:22,920:INFO:Copying training dataset
2025-06-07 21:59:22,923:INFO:Defining folds
2025-06-07 21:59:22,923:INFO:Declaring metric variables
2025-06-07 21:59:22,924:INFO:Importing untrained model
2025-06-07 21:59:22,924:INFO:Decision Tree Classifier Imported successfully
2025-06-07 21:59:22,924:INFO:Starting cross validation
2025-06-07 21:59:22,925:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-07 21:59:23,039:INFO:Calculating mean and std
2025-06-07 21:59:23,040:INFO:Creating metrics dataframe
2025-06-07 21:59:23,042:INFO:Uploading results into container
2025-06-07 21:59:23,042:INFO:Uploading model into container now
2025-06-07 21:59:23,043:INFO:_master_model_container: 4
2025-06-07 21:59:23,043:INFO:_display_container: 2
2025-06-07 21:59:23,043:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=131, splitter='best')
2025-06-07 21:59:23,043:INFO:create_model() successfully completed......................................
2025-06-07 21:59:23,138:INFO:SubProcess create_model() end ==================================
2025-06-07 21:59:23,138:INFO:Creating metrics dataframe
2025-06-07 21:59:23,140:INFO:Initializing SVM - Linear Kernel
2025-06-07 21:59:23,140:INFO:Total runtime is 0.21403375069300334 minutes
2025-06-07 21:59:23,140:INFO:SubProcess create_model() called ==================================
2025-06-07 21:59:23,140:INFO:Initializing create_model()
2025-06-07 21:59:23,140:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002099F6B5D10>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209EAB81950>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-07 21:59:23,140:INFO:Checking exceptions
2025-06-07 21:59:23,140:INFO:Importing libraries
2025-06-07 21:59:23,140:INFO:Copying training dataset
2025-06-07 21:59:23,143:INFO:Defining folds
2025-06-07 21:59:23,144:INFO:Declaring metric variables
2025-06-07 21:59:23,144:INFO:Importing untrained model
2025-06-07 21:59:23,144:INFO:SVM - Linear Kernel Imported successfully
2025-06-07 21:59:23,144:INFO:Starting cross validation
2025-06-07 21:59:23,145:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-07 21:59:23,226:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 21:59:23,233:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 21:59:23,235:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 21:59:23,240:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 21:59:23,243:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 21:59:23,254:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 21:59:23,269:INFO:Calculating mean and std
2025-06-07 21:59:23,269:INFO:Creating metrics dataframe
2025-06-07 21:59:23,271:INFO:Uploading results into container
2025-06-07 21:59:23,272:INFO:Uploading model into container now
2025-06-07 21:59:23,272:INFO:_master_model_container: 5
2025-06-07 21:59:23,272:INFO:_display_container: 2
2025-06-07 21:59:23,272:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=131, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-06-07 21:59:23,272:INFO:create_model() successfully completed......................................
2025-06-07 21:59:23,367:INFO:SubProcess create_model() end ==================================
2025-06-07 21:59:23,367:INFO:Creating metrics dataframe
2025-06-07 21:59:23,369:INFO:Initializing Ridge Classifier
2025-06-07 21:59:23,369:INFO:Total runtime is 0.2178561568260193 minutes
2025-06-07 21:59:23,369:INFO:SubProcess create_model() called ==================================
2025-06-07 21:59:23,369:INFO:Initializing create_model()
2025-06-07 21:59:23,369:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002099F6B5D10>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209EAB81950>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-07 21:59:23,369:INFO:Checking exceptions
2025-06-07 21:59:23,369:INFO:Importing libraries
2025-06-07 21:59:23,369:INFO:Copying training dataset
2025-06-07 21:59:23,372:INFO:Defining folds
2025-06-07 21:59:23,373:INFO:Declaring metric variables
2025-06-07 21:59:23,373:INFO:Importing untrained model
2025-06-07 21:59:23,373:INFO:Ridge Classifier Imported successfully
2025-06-07 21:59:23,373:INFO:Starting cross validation
2025-06-07 21:59:23,374:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-07 21:59:23,475:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 21:59:23,481:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 21:59:23,483:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 21:59:23,483:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 21:59:23,487:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 21:59:23,490:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 21:59:23,497:INFO:Calculating mean and std
2025-06-07 21:59:23,498:INFO:Creating metrics dataframe
2025-06-07 21:59:23,499:INFO:Uploading results into container
2025-06-07 21:59:23,500:INFO:Uploading model into container now
2025-06-07 21:59:23,501:INFO:_master_model_container: 6
2025-06-07 21:59:23,501:INFO:_display_container: 2
2025-06-07 21:59:23,501:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=131, solver='auto',
                tol=0.0001)
2025-06-07 21:59:23,501:INFO:create_model() successfully completed......................................
2025-06-07 21:59:23,611:INFO:SubProcess create_model() end ==================================
2025-06-07 21:59:23,611:INFO:Creating metrics dataframe
2025-06-07 21:59:23,613:INFO:Initializing Random Forest Classifier
2025-06-07 21:59:23,613:INFO:Total runtime is 0.2219177524248759 minutes
2025-06-07 21:59:23,613:INFO:SubProcess create_model() called ==================================
2025-06-07 21:59:23,613:INFO:Initializing create_model()
2025-06-07 21:59:23,613:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002099F6B5D10>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209EAB81950>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-07 21:59:23,613:INFO:Checking exceptions
2025-06-07 21:59:23,613:INFO:Importing libraries
2025-06-07 21:59:23,613:INFO:Copying training dataset
2025-06-07 21:59:23,616:INFO:Defining folds
2025-06-07 21:59:23,617:INFO:Declaring metric variables
2025-06-07 21:59:23,617:INFO:Importing untrained model
2025-06-07 21:59:23,617:INFO:Random Forest Classifier Imported successfully
2025-06-07 21:59:23,617:INFO:Starting cross validation
2025-06-07 21:59:23,618:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-07 21:59:23,928:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 21:59:23,940:INFO:Calculating mean and std
2025-06-07 21:59:23,941:INFO:Creating metrics dataframe
2025-06-07 21:59:23,943:INFO:Uploading results into container
2025-06-07 21:59:23,943:INFO:Uploading model into container now
2025-06-07 21:59:23,944:INFO:_master_model_container: 7
2025-06-07 21:59:23,944:INFO:_display_container: 2
2025-06-07 21:59:23,944:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=131, verbose=0,
                       warm_start=False)
2025-06-07 21:59:23,944:INFO:create_model() successfully completed......................................
2025-06-07 21:59:24,045:INFO:SubProcess create_model() end ==================================
2025-06-07 21:59:24,046:INFO:Creating metrics dataframe
2025-06-07 21:59:24,047:INFO:Initializing Quadratic Discriminant Analysis
2025-06-07 21:59:24,048:INFO:Total runtime is 0.2291512926419576 minutes
2025-06-07 21:59:24,048:INFO:SubProcess create_model() called ==================================
2025-06-07 21:59:24,048:INFO:Initializing create_model()
2025-06-07 21:59:24,048:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002099F6B5D10>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209EAB81950>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-07 21:59:24,048:INFO:Checking exceptions
2025-06-07 21:59:24,048:INFO:Importing libraries
2025-06-07 21:59:24,048:INFO:Copying training dataset
2025-06-07 21:59:24,051:INFO:Defining folds
2025-06-07 21:59:24,051:INFO:Declaring metric variables
2025-06-07 21:59:24,051:INFO:Importing untrained model
2025-06-07 21:59:24,052:INFO:Quadratic Discriminant Analysis Imported successfully
2025-06-07 21:59:24,052:INFO:Starting cross validation
2025-06-07 21:59:24,053:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-07 21:59:24,115:WARNING:C:\env\ml\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-06-07 21:59:24,116:WARNING:C:\env\ml\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-06-07 21:59:24,116:WARNING:C:\env\ml\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-06-07 21:59:24,121:WARNING:C:\env\ml\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-06-07 21:59:24,121:WARNING:C:\env\ml\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-06-07 21:59:24,122:WARNING:C:\env\ml\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-06-07 21:59:24,122:WARNING:C:\env\ml\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-06-07 21:59:24,122:WARNING:C:\env\ml\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-06-07 21:59:24,165:INFO:Calculating mean and std
2025-06-07 21:59:24,166:INFO:Creating metrics dataframe
2025-06-07 21:59:24,167:INFO:Uploading results into container
2025-06-07 21:59:24,168:INFO:Uploading model into container now
2025-06-07 21:59:24,168:INFO:_master_model_container: 8
2025-06-07 21:59:24,168:INFO:_display_container: 2
2025-06-07 21:59:24,168:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-06-07 21:59:24,168:INFO:create_model() successfully completed......................................
2025-06-07 21:59:24,255:INFO:SubProcess create_model() end ==================================
2025-06-07 21:59:24,256:INFO:Creating metrics dataframe
2025-06-07 21:59:24,257:INFO:Initializing Ada Boost Classifier
2025-06-07 21:59:24,257:INFO:Total runtime is 0.2326525370279948 minutes
2025-06-07 21:59:24,258:INFO:SubProcess create_model() called ==================================
2025-06-07 21:59:24,258:INFO:Initializing create_model()
2025-06-07 21:59:24,258:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002099F6B5D10>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209EAB81950>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-07 21:59:24,258:INFO:Checking exceptions
2025-06-07 21:59:24,258:INFO:Importing libraries
2025-06-07 21:59:24,258:INFO:Copying training dataset
2025-06-07 21:59:24,260:INFO:Defining folds
2025-06-07 21:59:24,260:INFO:Declaring metric variables
2025-06-07 21:59:24,260:INFO:Importing untrained model
2025-06-07 21:59:24,260:INFO:Ada Boost Classifier Imported successfully
2025-06-07 21:59:24,261:INFO:Starting cross validation
2025-06-07 21:59:24,261:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-07 21:59:24,314:WARNING:C:\env\ml\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-06-07 21:59:24,314:WARNING:C:\env\ml\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-06-07 21:59:24,314:WARNING:C:\env\ml\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-06-07 21:59:24,319:WARNING:C:\env\ml\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-06-07 21:59:24,322:WARNING:C:\env\ml\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-06-07 21:59:24,322:WARNING:C:\env\ml\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-06-07 21:59:24,325:WARNING:C:\env\ml\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-06-07 21:59:24,325:WARNING:C:\env\ml\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-06-07 21:59:24,447:INFO:Calculating mean and std
2025-06-07 21:59:24,448:INFO:Creating metrics dataframe
2025-06-07 21:59:24,450:INFO:Uploading results into container
2025-06-07 21:59:24,450:INFO:Uploading model into container now
2025-06-07 21:59:24,450:INFO:_master_model_container: 9
2025-06-07 21:59:24,450:INFO:_display_container: 2
2025-06-07 21:59:24,451:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=131)
2025-06-07 21:59:24,451:INFO:create_model() successfully completed......................................
2025-06-07 21:59:24,540:INFO:SubProcess create_model() end ==================================
2025-06-07 21:59:24,540:INFO:Creating metrics dataframe
2025-06-07 21:59:24,542:INFO:Initializing Gradient Boosting Classifier
2025-06-07 21:59:24,542:INFO:Total runtime is 0.23739525477091472 minutes
2025-06-07 21:59:24,542:INFO:SubProcess create_model() called ==================================
2025-06-07 21:59:24,542:INFO:Initializing create_model()
2025-06-07 21:59:24,542:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002099F6B5D10>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209EAB81950>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-07 21:59:24,542:INFO:Checking exceptions
2025-06-07 21:59:24,542:INFO:Importing libraries
2025-06-07 21:59:24,542:INFO:Copying training dataset
2025-06-07 21:59:24,544:INFO:Defining folds
2025-06-07 21:59:24,544:INFO:Declaring metric variables
2025-06-07 21:59:24,544:INFO:Importing untrained model
2025-06-07 21:59:24,545:INFO:Gradient Boosting Classifier Imported successfully
2025-06-07 21:59:24,545:INFO:Starting cross validation
2025-06-07 21:59:24,546:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-07 21:59:26,511:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 21:59:26,522:INFO:Calculating mean and std
2025-06-07 21:59:26,523:INFO:Creating metrics dataframe
2025-06-07 21:59:26,525:INFO:Uploading results into container
2025-06-07 21:59:26,525:INFO:Uploading model into container now
2025-06-07 21:59:26,525:INFO:_master_model_container: 10
2025-06-07 21:59:26,526:INFO:_display_container: 2
2025-06-07 21:59:26,526:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=131, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-06-07 21:59:26,526:INFO:create_model() successfully completed......................................
2025-06-07 21:59:26,619:INFO:SubProcess create_model() end ==================================
2025-06-07 21:59:26,619:INFO:Creating metrics dataframe
2025-06-07 21:59:26,621:INFO:Initializing Linear Discriminant Analysis
2025-06-07 21:59:26,621:INFO:Total runtime is 0.2720544735590617 minutes
2025-06-07 21:59:26,621:INFO:SubProcess create_model() called ==================================
2025-06-07 21:59:26,621:INFO:Initializing create_model()
2025-06-07 21:59:26,621:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002099F6B5D10>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209EAB81950>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-07 21:59:26,621:INFO:Checking exceptions
2025-06-07 21:59:26,621:INFO:Importing libraries
2025-06-07 21:59:26,622:INFO:Copying training dataset
2025-06-07 21:59:26,625:INFO:Defining folds
2025-06-07 21:59:26,625:INFO:Declaring metric variables
2025-06-07 21:59:26,625:INFO:Importing untrained model
2025-06-07 21:59:26,625:INFO:Linear Discriminant Analysis Imported successfully
2025-06-07 21:59:26,625:INFO:Starting cross validation
2025-06-07 21:59:26,627:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-07 21:59:26,712:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 21:59:26,713:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 21:59:26,717:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 21:59:26,719:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 21:59:26,733:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 21:59:26,741:INFO:Calculating mean and std
2025-06-07 21:59:26,742:INFO:Creating metrics dataframe
2025-06-07 21:59:26,744:INFO:Uploading results into container
2025-06-07 21:59:26,744:INFO:Uploading model into container now
2025-06-07 21:59:26,744:INFO:_master_model_container: 11
2025-06-07 21:59:26,744:INFO:_display_container: 2
2025-06-07 21:59:26,745:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-06-07 21:59:26,745:INFO:create_model() successfully completed......................................
2025-06-07 21:59:26,833:INFO:SubProcess create_model() end ==================================
2025-06-07 21:59:26,833:INFO:Creating metrics dataframe
2025-06-07 21:59:26,835:INFO:Initializing Extra Trees Classifier
2025-06-07 21:59:26,835:INFO:Total runtime is 0.27561731735865275 minutes
2025-06-07 21:59:26,835:INFO:SubProcess create_model() called ==================================
2025-06-07 21:59:26,835:INFO:Initializing create_model()
2025-06-07 21:59:26,835:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002099F6B5D10>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209EAB81950>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-07 21:59:26,835:INFO:Checking exceptions
2025-06-07 21:59:26,835:INFO:Importing libraries
2025-06-07 21:59:26,835:INFO:Copying training dataset
2025-06-07 21:59:26,838:INFO:Defining folds
2025-06-07 21:59:26,838:INFO:Declaring metric variables
2025-06-07 21:59:26,838:INFO:Importing untrained model
2025-06-07 21:59:26,838:INFO:Extra Trees Classifier Imported successfully
2025-06-07 21:59:26,838:INFO:Starting cross validation
2025-06-07 21:59:26,839:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-07 21:59:27,139:INFO:Calculating mean and std
2025-06-07 21:59:27,139:INFO:Creating metrics dataframe
2025-06-07 21:59:27,141:INFO:Uploading results into container
2025-06-07 21:59:27,141:INFO:Uploading model into container now
2025-06-07 21:59:27,141:INFO:_master_model_container: 12
2025-06-07 21:59:27,141:INFO:_display_container: 2
2025-06-07 21:59:27,142:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=131, verbose=0,
                     warm_start=False)
2025-06-07 21:59:27,142:INFO:create_model() successfully completed......................................
2025-06-07 21:59:27,236:INFO:SubProcess create_model() end ==================================
2025-06-07 21:59:27,236:INFO:Creating metrics dataframe
2025-06-07 21:59:27,238:INFO:Initializing Light Gradient Boosting Machine
2025-06-07 21:59:27,238:INFO:Total runtime is 0.28233140309651694 minutes
2025-06-07 21:59:27,238:INFO:SubProcess create_model() called ==================================
2025-06-07 21:59:27,238:INFO:Initializing create_model()
2025-06-07 21:59:27,238:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002099F6B5D10>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209EAB81950>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-07 21:59:27,238:INFO:Checking exceptions
2025-06-07 21:59:27,238:INFO:Importing libraries
2025-06-07 21:59:27,239:INFO:Copying training dataset
2025-06-07 21:59:27,241:INFO:Defining folds
2025-06-07 21:59:27,241:INFO:Declaring metric variables
2025-06-07 21:59:27,241:INFO:Importing untrained model
2025-06-07 21:59:27,242:INFO:Light Gradient Boosting Machine Imported successfully
2025-06-07 21:59:27,242:INFO:Starting cross validation
2025-06-07 21:59:27,243:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-07 21:59:27,818:INFO:Calculating mean and std
2025-06-07 21:59:27,819:INFO:Creating metrics dataframe
2025-06-07 21:59:27,821:INFO:Uploading results into container
2025-06-07 21:59:27,821:INFO:Uploading model into container now
2025-06-07 21:59:27,822:INFO:_master_model_container: 13
2025-06-07 21:59:27,822:INFO:_display_container: 2
2025-06-07 21:59:27,822:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=131, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-06-07 21:59:27,822:INFO:create_model() successfully completed......................................
2025-06-07 21:59:27,939:INFO:SubProcess create_model() end ==================================
2025-06-07 21:59:27,939:INFO:Creating metrics dataframe
2025-06-07 21:59:27,941:INFO:Initializing Dummy Classifier
2025-06-07 21:59:27,941:INFO:Total runtime is 0.2940432866414388 minutes
2025-06-07 21:59:27,941:INFO:SubProcess create_model() called ==================================
2025-06-07 21:59:27,941:INFO:Initializing create_model()
2025-06-07 21:59:27,941:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002099F6B5D10>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209EAB81950>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-07 21:59:27,941:INFO:Checking exceptions
2025-06-07 21:59:27,942:INFO:Importing libraries
2025-06-07 21:59:27,942:INFO:Copying training dataset
2025-06-07 21:59:27,944:INFO:Defining folds
2025-06-07 21:59:27,944:INFO:Declaring metric variables
2025-06-07 21:59:27,945:INFO:Importing untrained model
2025-06-07 21:59:27,945:INFO:Dummy Classifier Imported successfully
2025-06-07 21:59:27,945:INFO:Starting cross validation
2025-06-07 21:59:27,946:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-07 21:59:28,030:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 21:59:28,034:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 21:59:28,035:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 21:59:28,035:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 21:59:28,041:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 21:59:28,042:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 21:59:28,043:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 21:59:28,044:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 21:59:28,048:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 21:59:28,058:INFO:Calculating mean and std
2025-06-07 21:59:28,059:INFO:Creating metrics dataframe
2025-06-07 21:59:28,060:INFO:Uploading results into container
2025-06-07 21:59:28,061:INFO:Uploading model into container now
2025-06-07 21:59:28,061:INFO:_master_model_container: 14
2025-06-07 21:59:28,061:INFO:_display_container: 2
2025-06-07 21:59:28,061:INFO:DummyClassifier(constant=None, random_state=131, strategy='prior')
2025-06-07 21:59:28,061:INFO:create_model() successfully completed......................................
2025-06-07 21:59:28,159:INFO:SubProcess create_model() end ==================================
2025-06-07 21:59:28,160:INFO:Creating metrics dataframe
2025-06-07 21:59:28,163:WARNING:C:\env\ml\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-06-07 21:59:28,164:INFO:Initializing create_model()
2025-06-07 21:59:28,164:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002099F6B5D10>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=131, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-07 21:59:28,165:INFO:Checking exceptions
2025-06-07 21:59:28,165:INFO:Importing libraries
2025-06-07 21:59:28,165:INFO:Copying training dataset
2025-06-07 21:59:28,168:INFO:Defining folds
2025-06-07 21:59:28,168:INFO:Declaring metric variables
2025-06-07 21:59:28,168:INFO:Importing untrained model
2025-06-07 21:59:28,168:INFO:Declaring custom model
2025-06-07 21:59:28,169:INFO:Random Forest Classifier Imported successfully
2025-06-07 21:59:28,170:INFO:Cross validation set to False
2025-06-07 21:59:28,170:INFO:Fitting Model
2025-06-07 21:59:28,307:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=131, verbose=0,
                       warm_start=False)
2025-06-07 21:59:28,307:INFO:create_model() successfully completed......................................
2025-06-07 21:59:28,401:INFO:Creating Dashboard logs
2025-06-07 21:59:28,401:INFO:Model: Random Forest Classifier
2025-06-07 21:59:28,462:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 131, 'verbose': 0, 'warm_start': False}
2025-06-07 21:59:28,591:INFO:Initializing predict_model()
2025-06-07 21:59:28,592:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002099F6B5D10>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=131, verbose=0,
                       warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000209EB3D3EC0>)
2025-06-07 21:59:28,592:INFO:Checking exceptions
2025-06-07 21:59:28,592:INFO:Preloading libraries
2025-06-07 21:59:28,830:INFO:SubProcess plot_model() called ==================================
2025-06-07 21:59:28,831:INFO:Initializing plot_model()
2025-06-07 21:59:28,831:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002099F6B5D10>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=131, verbose=0,
                       warm_start=False), plot=auc, scale=1, save=C:\Users\JOSECA~1\AppData\Local\Temp\tmpmhh6wj2s, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=False, display=None, display_format=None)
2025-06-07 21:59:28,831:INFO:Checking exceptions
2025-06-07 21:59:28,850:INFO:Preloading libraries
2025-06-07 21:59:28,856:INFO:Copying training dataset
2025-06-07 21:59:28,856:INFO:Plot type: auc
2025-06-07 21:59:29,854:INFO:Fitting Model
2025-06-07 21:59:29,864:WARNING:C:\env\ml\Lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names
  warnings.warn(

2025-06-07 21:59:29,865:INFO:Scoring test/hold-out set
2025-06-07 21:59:29,918:INFO:Saving 'C:\Users\JOSECA~1\AppData\Local\Temp\tmpmhh6wj2s\AUC.png'
2025-06-07 21:59:30,049:INFO:Visual Rendered Successfully
2025-06-07 21:59:30,168:INFO:plot_model() successfully completed......................................
2025-06-07 21:59:30,172:INFO:Initializing plot_model()
2025-06-07 21:59:30,172:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002099F6B5D10>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=131, verbose=0,
                       warm_start=False), plot=confusion_matrix, scale=1, save=C:\Users\JOSECA~1\AppData\Local\Temp\tmpmhh6wj2s, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=False, display=None, display_format=None)
2025-06-07 21:59:30,172:INFO:Checking exceptions
2025-06-07 21:59:30,193:INFO:Preloading libraries
2025-06-07 21:59:30,198:INFO:Copying training dataset
2025-06-07 21:59:30,198:INFO:Plot type: confusion_matrix
2025-06-07 21:59:30,443:INFO:Fitting Model
2025-06-07 21:59:30,443:WARNING:C:\env\ml\Lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names
  warnings.warn(

2025-06-07 21:59:30,443:INFO:Scoring test/hold-out set
2025-06-07 21:59:30,493:INFO:Saving 'C:\Users\JOSECA~1\AppData\Local\Temp\tmpmhh6wj2s\Confusion Matrix.png'
2025-06-07 21:59:30,557:INFO:Visual Rendered Successfully
2025-06-07 21:59:30,666:INFO:plot_model() successfully completed......................................
2025-06-07 21:59:30,671:INFO:Initializing plot_model()
2025-06-07 21:59:30,671:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002099F6B5D10>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=131, verbose=0,
                       warm_start=False), plot=feature, scale=1, save=C:\Users\JOSECA~1\AppData\Local\Temp\tmpmhh6wj2s, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=False, display=None, display_format=None)
2025-06-07 21:59:30,671:INFO:Checking exceptions
2025-06-07 21:59:30,690:INFO:Preloading libraries
2025-06-07 21:59:30,695:INFO:Copying training dataset
2025-06-07 21:59:30,695:INFO:Plot type: feature
2025-06-07 21:59:30,695:WARNING:No coef_ found. Trying feature_importances_
2025-06-07 21:59:30,839:INFO:Saving 'C:\Users\JOSECA~1\AppData\Local\Temp\tmpmhh6wj2s\Feature Importance.png'
2025-06-07 21:59:30,931:INFO:Visual Rendered Successfully
2025-06-07 21:59:31,029:INFO:plot_model() successfully completed......................................
2025-06-07 21:59:31,033:INFO:SubProcess plot_model() end ==================================
2025-06-07 21:59:31,039:WARNING:C:\env\ml\Lib\site-packages\_distutils_hack\__init__.py:33: UserWarning: Setuptools is replacing distutils.
  warnings.warn("Setuptools is replacing distutils.")

2025-06-07 21:59:33,564:INFO:Creating Dashboard logs
2025-06-07 21:59:33,564:INFO:Model: Dummy Classifier
2025-06-07 21:59:33,605:INFO:Logged params: {'constant': None, 'random_state': 131, 'strategy': 'prior'}
2025-06-07 21:59:33,857:INFO:Creating Dashboard logs
2025-06-07 21:59:33,857:INFO:Model: Ridge Classifier
2025-06-07 21:59:33,901:INFO:Logged params: {'alpha': 1.0, 'class_weight': None, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': 131, 'solver': 'auto', 'tol': 0.0001}
2025-06-07 21:59:34,168:INFO:Creating Dashboard logs
2025-06-07 21:59:34,168:INFO:Model: Logistic Regression
2025-06-07 21:59:34,212:INFO:Logged params: {'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': 131, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}
2025-06-07 21:59:34,482:INFO:Creating Dashboard logs
2025-06-07 21:59:34,482:INFO:Model: Linear Discriminant Analysis
2025-06-07 21:59:34,527:INFO:Logged params: {'covariance_estimator': None, 'n_components': None, 'priors': None, 'shrinkage': None, 'solver': 'svd', 'store_covariance': False, 'tol': 0.0001}
2025-06-07 21:59:34,798:INFO:Creating Dashboard logs
2025-06-07 21:59:34,799:INFO:Model: Extra Trees Classifier
2025-06-07 21:59:34,851:INFO:Logged params: {'bootstrap': False, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 131, 'verbose': 0, 'warm_start': False}
2025-06-07 21:59:35,163:INFO:Creating Dashboard logs
2025-06-07 21:59:35,164:INFO:Model: K Neighbors Classifier
2025-06-07 21:59:35,217:INFO:Logged params: {'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 5, 'p': 2, 'weights': 'uniform'}
2025-06-07 21:59:35,512:INFO:Creating Dashboard logs
2025-06-07 21:59:35,513:INFO:Model: Decision Tree Classifier
2025-06-07 21:59:35,559:INFO:Logged params: {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'random_state': 131, 'splitter': 'best'}
2025-06-07 21:59:35,850:INFO:Creating Dashboard logs
2025-06-07 21:59:35,851:INFO:Model: Gradient Boosting Classifier
2025-06-07 21:59:35,907:INFO:Logged params: {'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'log_loss', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 131, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2025-06-07 21:59:36,187:INFO:Creating Dashboard logs
2025-06-07 21:59:36,187:INFO:Model: Ada Boost Classifier
2025-06-07 21:59:36,230:INFO:Logged params: {'algorithm': 'SAMME.R', 'estimator': None, 'learning_rate': 1.0, 'n_estimators': 50, 'random_state': 131}
2025-06-07 21:59:36,480:INFO:Creating Dashboard logs
2025-06-07 21:59:36,481:INFO:Model: Naive Bayes
2025-06-07 21:59:36,526:INFO:Logged params: {'priors': None, 'var_smoothing': 1e-09}
2025-06-07 21:59:36,786:INFO:Creating Dashboard logs
2025-06-07 21:59:36,787:INFO:Model: Light Gradient Boosting Machine
2025-06-07 21:59:36,830:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 131, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2025-06-07 21:59:37,096:INFO:Creating Dashboard logs
2025-06-07 21:59:37,096:INFO:Model: SVM - Linear Kernel
2025-06-07 21:59:37,142:INFO:Logged params: {'alpha': 0.0001, 'average': False, 'class_weight': None, 'early_stopping': False, 'epsilon': 0.1, 'eta0': 0.001, 'fit_intercept': True, 'l1_ratio': 0.15, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1000, 'n_iter_no_change': 5, 'n_jobs': -1, 'penalty': 'l2', 'power_t': 0.5, 'random_state': 131, 'shuffle': True, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2025-06-07 21:59:37,416:INFO:Creating Dashboard logs
2025-06-07 21:59:37,417:INFO:Model: Quadratic Discriminant Analysis
2025-06-07 21:59:37,460:INFO:Logged params: {'priors': None, 'reg_param': 0.0, 'store_covariance': False, 'tol': 0.0001}
2025-06-07 21:59:37,712:INFO:_master_model_container: 14
2025-06-07 21:59:37,712:INFO:_display_container: 2
2025-06-07 21:59:37,712:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=131, verbose=0,
                       warm_start=False)
2025-06-07 21:59:37,712:INFO:compare_models() successfully completed......................................
2025-06-07 21:59:37,714:INFO:Initializing tune_model()
2025-06-07 21:59:37,714:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002099F6B5D10>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=131, verbose=0,
                       warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-06-07 21:59:37,714:INFO:Checking exceptions
2025-06-07 21:59:37,716:INFO:Copying training dataset
2025-06-07 21:59:37,718:INFO:Checking base model
2025-06-07 21:59:37,718:INFO:Base model : Random Forest Classifier
2025-06-07 21:59:37,718:INFO:Declaring metric variables
2025-06-07 21:59:37,718:INFO:Defining Hyperparameters
2025-06-07 21:59:37,829:INFO:Tuning with n_jobs=-1
2025-06-07 21:59:37,829:INFO:Initializing RandomizedSearchCV
2025-06-07 21:59:41,268:INFO:best_params: {'actual_estimator__n_estimators': 290, 'actual_estimator__min_samples_split': 10, 'actual_estimator__min_samples_leaf': 5, 'actual_estimator__min_impurity_decrease': 0.2, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 7, 'actual_estimator__criterion': 'gini', 'actual_estimator__class_weight': 'balanced', 'actual_estimator__bootstrap': False}
2025-06-07 21:59:41,268:INFO:Hyperparameter search completed
2025-06-07 21:59:41,268:INFO:SubProcess create_model() called ==================================
2025-06-07 21:59:41,270:INFO:Initializing create_model()
2025-06-07 21:59:41,270:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002099F6B5D10>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=131, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000209EAB54C90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_estimators': 290, 'min_samples_split': 10, 'min_samples_leaf': 5, 'min_impurity_decrease': 0.2, 'max_features': 1.0, 'max_depth': 7, 'criterion': 'gini', 'class_weight': 'balanced', 'bootstrap': False})
2025-06-07 21:59:41,270:INFO:Checking exceptions
2025-06-07 21:59:41,270:INFO:Importing libraries
2025-06-07 21:59:41,270:INFO:Copying training dataset
2025-06-07 21:59:41,273:INFO:Defining folds
2025-06-07 21:59:41,273:INFO:Declaring metric variables
2025-06-07 21:59:41,273:INFO:Importing untrained model
2025-06-07 21:59:41,273:INFO:Declaring custom model
2025-06-07 21:59:41,273:INFO:Random Forest Classifier Imported successfully
2025-06-07 21:59:41,274:INFO:Starting cross validation
2025-06-07 21:59:41,274:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-07 21:59:41,800:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 21:59:41,805:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 21:59:41,817:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 21:59:41,820:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 21:59:41,838:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 21:59:41,844:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 21:59:41,853:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 21:59:41,855:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 21:59:41,857:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 21:59:41,862:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 21:59:41,870:INFO:Calculating mean and std
2025-06-07 21:59:41,871:INFO:Creating metrics dataframe
2025-06-07 21:59:41,872:INFO:Finalizing model
2025-06-07 21:59:42,122:INFO:Uploading results into container
2025-06-07 21:59:42,122:INFO:Uploading model into container now
2025-06-07 21:59:42,122:INFO:_master_model_container: 15
2025-06-07 21:59:42,123:INFO:_display_container: 3
2025-06-07 21:59:42,123:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight='balanced',
                       criterion='gini', max_depth=7, max_features=1.0,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.2, min_samples_leaf=5,
                       min_samples_split=10, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=290, n_jobs=-1,
                       oob_score=False, random_state=131, verbose=0,
                       warm_start=False)
2025-06-07 21:59:42,123:INFO:create_model() successfully completed......................................
2025-06-07 21:59:42,223:INFO:SubProcess create_model() end ==================================
2025-06-07 21:59:42,223:INFO:choose_better activated
2025-06-07 21:59:42,223:INFO:SubProcess create_model() called ==================================
2025-06-07 21:59:42,224:INFO:Initializing create_model()
2025-06-07 21:59:42,224:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002099F6B5D10>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=131, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-07 21:59:42,224:INFO:Checking exceptions
2025-06-07 21:59:42,224:INFO:Importing libraries
2025-06-07 21:59:42,224:INFO:Copying training dataset
2025-06-07 21:59:42,227:INFO:Defining folds
2025-06-07 21:59:42,227:INFO:Declaring metric variables
2025-06-07 21:59:42,227:INFO:Importing untrained model
2025-06-07 21:59:42,227:INFO:Declaring custom model
2025-06-07 21:59:42,227:INFO:Random Forest Classifier Imported successfully
2025-06-07 21:59:42,228:INFO:Starting cross validation
2025-06-07 21:59:42,228:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-07 21:59:42,569:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 21:59:42,587:INFO:Calculating mean and std
2025-06-07 21:59:42,587:INFO:Creating metrics dataframe
2025-06-07 21:59:42,590:INFO:Finalizing model
2025-06-07 21:59:42,732:INFO:Uploading results into container
2025-06-07 21:59:42,733:INFO:Uploading model into container now
2025-06-07 21:59:42,733:INFO:_master_model_container: 16
2025-06-07 21:59:42,733:INFO:_display_container: 4
2025-06-07 21:59:42,734:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=131, verbose=0,
                       warm_start=False)
2025-06-07 21:59:42,734:INFO:create_model() successfully completed......................................
2025-06-07 21:59:42,830:INFO:SubProcess create_model() end ==================================
2025-06-07 21:59:42,830:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=131, verbose=0,
                       warm_start=False) result for Accuracy is 0.7114
2025-06-07 21:59:42,832:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight='balanced',
                       criterion='gini', max_depth=7, max_features=1.0,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.2, min_samples_leaf=5,
                       min_samples_split=10, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=290, n_jobs=-1,
                       oob_score=False, random_state=131, verbose=0,
                       warm_start=False) result for Accuracy is 0.7086
2025-06-07 21:59:42,832:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=131, verbose=0,
                       warm_start=False) is best model
2025-06-07 21:59:42,832:INFO:choose_better completed
2025-06-07 21:59:42,832:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-06-07 21:59:42,832:INFO:Creating Dashboard logs
2025-06-07 21:59:42,833:INFO:Model: Random Forest Classifier
2025-06-07 21:59:42,892:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 131, 'verbose': 0, 'warm_start': False}
2025-06-07 21:59:43,016:INFO:Initializing predict_model()
2025-06-07 21:59:43,016:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002099F6B5D10>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=131, verbose=0,
                       warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000209EB012C00>)
2025-06-07 21:59:43,016:INFO:Checking exceptions
2025-06-07 21:59:43,016:INFO:Preloading libraries
2025-06-07 21:59:43,239:INFO:SubProcess plot_model() called ==================================
2025-06-07 21:59:43,240:INFO:Initializing plot_model()
2025-06-07 21:59:43,240:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002099F6B5D10>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=131, verbose=0,
                       warm_start=False), plot=auc, scale=1, save=C:\Users\JOSECA~1\AppData\Local\Temp\tmpsn62i1_2, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=False, display=None, display_format=None)
2025-06-07 21:59:43,240:INFO:Checking exceptions
2025-06-07 21:59:43,259:INFO:Preloading libraries
2025-06-07 21:59:43,264:INFO:Copying training dataset
2025-06-07 21:59:43,265:INFO:Plot type: auc
2025-06-07 21:59:43,485:INFO:Fitting Model
2025-06-07 21:59:43,486:WARNING:C:\env\ml\Lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names
  warnings.warn(

2025-06-07 21:59:43,486:INFO:Scoring test/hold-out set
2025-06-07 21:59:43,533:INFO:Saving 'C:\Users\JOSECA~1\AppData\Local\Temp\tmpsn62i1_2\AUC.png'
2025-06-07 21:59:43,643:INFO:Visual Rendered Successfully
2025-06-07 21:59:43,751:INFO:plot_model() successfully completed......................................
2025-06-07 21:59:43,755:INFO:Initializing plot_model()
2025-06-07 21:59:43,755:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002099F6B5D10>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=131, verbose=0,
                       warm_start=False), plot=confusion_matrix, scale=1, save=C:\Users\JOSECA~1\AppData\Local\Temp\tmpsn62i1_2, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=False, display=None, display_format=None)
2025-06-07 21:59:43,755:INFO:Checking exceptions
2025-06-07 21:59:43,773:INFO:Preloading libraries
2025-06-07 21:59:43,778:INFO:Copying training dataset
2025-06-07 21:59:43,778:INFO:Plot type: confusion_matrix
2025-06-07 21:59:43,994:INFO:Fitting Model
2025-06-07 21:59:43,994:WARNING:C:\env\ml\Lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names
  warnings.warn(

2025-06-07 21:59:43,994:INFO:Scoring test/hold-out set
2025-06-07 21:59:44,041:INFO:Saving 'C:\Users\JOSECA~1\AppData\Local\Temp\tmpsn62i1_2\Confusion Matrix.png'
2025-06-07 21:59:44,097:INFO:Visual Rendered Successfully
2025-06-07 21:59:44,200:INFO:plot_model() successfully completed......................................
2025-06-07 21:59:44,205:INFO:Initializing plot_model()
2025-06-07 21:59:44,205:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002099F6B5D10>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=131, verbose=0,
                       warm_start=False), plot=feature, scale=1, save=C:\Users\JOSECA~1\AppData\Local\Temp\tmpsn62i1_2, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=False, display=None, display_format=None)
2025-06-07 21:59:44,205:INFO:Checking exceptions
2025-06-07 21:59:44,224:INFO:Preloading libraries
2025-06-07 21:59:44,229:INFO:Copying training dataset
2025-06-07 21:59:44,229:INFO:Plot type: feature
2025-06-07 21:59:44,229:WARNING:No coef_ found. Trying feature_importances_
2025-06-07 21:59:44,368:INFO:Saving 'C:\Users\JOSECA~1\AppData\Local\Temp\tmpsn62i1_2\Feature Importance.png'
2025-06-07 21:59:44,457:INFO:Visual Rendered Successfully
2025-06-07 21:59:44,554:INFO:plot_model() successfully completed......................................
2025-06-07 21:59:44,558:INFO:SubProcess plot_model() end ==================================
2025-06-07 21:59:44,745:INFO:_master_model_container: 16
2025-06-07 21:59:44,745:INFO:_display_container: 3
2025-06-07 21:59:44,746:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=131, verbose=0,
                       warm_start=False)
2025-06-07 21:59:44,746:INFO:tune_model() successfully completed......................................
2025-06-07 21:59:44,851:INFO:Initializing save_model()
2025-06-07 21:59:44,851:INFO:save_model(model=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=131, verbose=0,
                       warm_start=False), model_name=modelo_responde_oferta_mlflow, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\JOSECA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'ingreso_mensual',
                                             'usa_app', 'usa_web',
                                             'satisfaccion', 'num_productos',
                                             'reclamos_ult_6m',
                                             'tasa_credito'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_feature...
                                                                         'data_type': dtype('O'),
                                                                         'mapping': F      0
M      1
NaN   -1
dtype: int64}],
                                                               return_df=True,
                                                               verbose=0))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['nivel_educacion', 'region'],
                                    transformer=OneHotEncoder(cols=['nivel_educacion',
                                                                    'region'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-06-07 21:59:44,851:INFO:Adding model into prep_pipe
2025-06-07 21:59:44,882:INFO:modelo_responde_oferta_mlflow.pkl saved in current working directory
2025-06-07 21:59:44,895:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'ingreso_mensual',
                                             'usa_app', 'usa_web',
                                             'satisfaccion', 'num_productos',
                                             'reclamos_ult_6m',
                                             'tasa_credito'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean')...
                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,
                                        class_weight=None, criterion='gini',
                                        max_depth=None, max_features='sqrt',
                                        max_leaf_nodes=None, max_samples=None,
                                        min_impurity_decrease=0.0,
                                        min_samples_leaf=1, min_samples_split=2,
                                        min_weight_fraction_leaf=0.0,
                                        monotonic_cst=None, n_estimators=100,
                                        n_jobs=-1, oob_score=False,
                                        random_state=131, verbose=0,
                                        warm_start=False))],
         verbose=False)
2025-06-07 21:59:44,895:INFO:save_model() successfully completed......................................
2025-06-07 22:01:41,907:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-07 22:01:41,907:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-07 22:01:41,907:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-07 22:01:41,907:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-07 22:01:43,715:INFO:PyCaret ClassificationExperiment
2025-06-07 22:01:43,716:INFO:Logging name: respuesta-autoML
2025-06-07 22:01:43,716:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-06-07 22:01:43,716:INFO:version 3.3.2
2025-06-07 22:01:43,716:INFO:Initializing setup()
2025-06-07 22:01:43,716:INFO:self.USI: 0ddb
2025-06-07 22:01:43,716:INFO:self._variable_keys: {'y_test', 'fold_generator', '_ml_usecase', 'gpu_param', 'fold_groups_param', 'is_multiclass', 'log_plots_param', 'X_train', 'X', 'n_jobs_param', 'exp_name_log', 'html_param', 'data', 'y', 'gpu_n_jobs_param', 'fix_imbalance', 'exp_id', 'logging_param', 'memory', 'target_param', 'X_test', 'seed', 'USI', 'fold_shuffle_param', 'y_train', 'pipeline', 'idx', '_available_plots'}
2025-06-07 22:01:43,716:INFO:Checking environment
2025-06-07 22:01:43,716:INFO:python_version: 3.11.0
2025-06-07 22:01:43,716:INFO:python_build: ('main', 'Oct 24 2022 18:26:48')
2025-06-07 22:01:43,716:INFO:machine: AMD64
2025-06-07 22:01:43,739:INFO:platform: Windows-10-10.0.26100-SP0
2025-06-07 22:01:43,762:INFO:Memory: svmem(total=16438312960, available=2782965760, percent=83.1, used=13655347200, free=2782965760)
2025-06-07 22:01:43,762:INFO:Physical Core: 8
2025-06-07 22:01:43,762:INFO:Logical Core: 16
2025-06-07 22:01:43,762:INFO:Checking libraries
2025-06-07 22:01:43,762:INFO:System:
2025-06-07 22:01:43,762:INFO:    python: 3.11.0 (main, Oct 24 2022, 18:26:48) [MSC v.1933 64 bit (AMD64)]
2025-06-07 22:01:43,762:INFO:executable: C:\env\ml\Scripts\python.exe
2025-06-07 22:01:43,763:INFO:   machine: Windows-10-10.0.26100-SP0
2025-06-07 22:01:43,763:INFO:PyCaret required dependencies:
2025-06-07 22:01:43,821:INFO:                 pip: 22.3
2025-06-07 22:01:43,821:INFO:          setuptools: 65.5.0
2025-06-07 22:01:43,821:INFO:             pycaret: 3.3.2
2025-06-07 22:01:43,821:INFO:             IPython: 9.2.0
2025-06-07 22:01:43,821:INFO:          ipywidgets: 8.1.7
2025-06-07 22:01:43,821:INFO:                tqdm: 4.67.1
2025-06-07 22:01:43,821:INFO:               numpy: 1.26.4
2025-06-07 22:01:43,821:INFO:              pandas: 2.1.4
2025-06-07 22:01:43,821:INFO:              jinja2: 3.1.6
2025-06-07 22:01:43,821:INFO:               scipy: 1.11.4
2025-06-07 22:01:43,821:INFO:              joblib: 1.3.2
2025-06-07 22:01:43,821:INFO:             sklearn: 1.4.2
2025-06-07 22:01:43,821:INFO:                pyod: 2.0.5
2025-06-07 22:01:43,821:INFO:            imblearn: 0.13.0
2025-06-07 22:01:43,822:INFO:   category_encoders: 2.7.0
2025-06-07 22:01:43,822:INFO:            lightgbm: 4.6.0
2025-06-07 22:01:43,822:INFO:               numba: 0.61.0
2025-06-07 22:01:43,822:INFO:            requests: 2.32.3
2025-06-07 22:01:43,822:INFO:          matplotlib: 3.7.5
2025-06-07 22:01:43,822:INFO:          scikitplot: 0.3.7
2025-06-07 22:01:43,822:INFO:         yellowbrick: 1.5
2025-06-07 22:01:43,822:INFO:              plotly: 5.24.1
2025-06-07 22:01:43,822:INFO:    plotly-resampler: Not installed
2025-06-07 22:01:43,822:INFO:             kaleido: 0.2.1
2025-06-07 22:01:43,822:INFO:           schemdraw: 0.15
2025-06-07 22:01:43,822:INFO:         statsmodels: 0.14.4
2025-06-07 22:01:43,822:INFO:              sktime: 0.26.0
2025-06-07 22:01:43,822:INFO:               tbats: 1.1.3
2025-06-07 22:01:43,822:INFO:            pmdarima: 2.0.4
2025-06-07 22:01:43,822:INFO:              psutil: 7.0.0
2025-06-07 22:01:43,822:INFO:          markupsafe: 3.0.2
2025-06-07 22:01:43,822:INFO:             pickle5: Not installed
2025-06-07 22:01:43,822:INFO:         cloudpickle: 3.1.1
2025-06-07 22:01:43,822:INFO:         deprecation: 2.1.0
2025-06-07 22:01:43,822:INFO:              xxhash: 3.5.0
2025-06-07 22:01:43,822:INFO:           wurlitzer: Not installed
2025-06-07 22:01:43,822:INFO:PyCaret optional dependencies:
2025-06-07 22:01:43,981:INFO:                shap: 0.44.1
2025-06-07 22:01:43,982:INFO:           interpret: 0.6.10
2025-06-07 22:01:43,982:INFO:                umap: 0.5.7
2025-06-07 22:01:43,982:INFO:     ydata_profiling: 4.16.1
2025-06-07 22:01:43,982:INFO:  explainerdashboard: 0.4.8
2025-06-07 22:01:43,982:INFO:             autoviz: Not installed
2025-06-07 22:01:43,982:INFO:           fairlearn: 0.7.0
2025-06-07 22:01:43,982:INFO:          deepchecks: Not installed
2025-06-07 22:01:43,982:INFO:             xgboost: Not installed
2025-06-07 22:01:43,982:INFO:            catboost: Not installed
2025-06-07 22:01:43,982:INFO:              kmodes: Not installed
2025-06-07 22:01:43,982:INFO:             mlxtend: Not installed
2025-06-07 22:01:43,982:INFO:       statsforecast: Not installed
2025-06-07 22:01:43,982:INFO:        tune_sklearn: Not installed
2025-06-07 22:01:43,982:INFO:                 ray: Not installed
2025-06-07 22:01:43,982:INFO:            hyperopt: Not installed
2025-06-07 22:01:43,982:INFO:              optuna: Not installed
2025-06-07 22:01:43,982:INFO:               skopt: Not installed
2025-06-07 22:01:43,982:INFO:              mlflow: 2.22.0
2025-06-07 22:01:43,982:INFO:              gradio: Not installed
2025-06-07 22:01:43,982:INFO:             fastapi: 0.115.12
2025-06-07 22:01:43,982:INFO:             uvicorn: 0.34.2
2025-06-07 22:01:43,982:INFO:              m2cgen: Not installed
2025-06-07 22:01:43,982:INFO:           evidently: Not installed
2025-06-07 22:01:43,982:INFO:               fugue: Not installed
2025-06-07 22:01:43,982:INFO:           streamlit: Not installed
2025-06-07 22:01:43,982:INFO:             prophet: Not installed
2025-06-07 22:01:43,982:INFO:None
2025-06-07 22:01:43,983:INFO:Set up data.
2025-06-07 22:01:43,987:INFO:Set up folding strategy.
2025-06-07 22:01:43,987:INFO:Set up train/test split.
2025-06-07 22:01:43,993:INFO:Set up index.
2025-06-07 22:01:43,994:INFO:Assigning column types.
2025-06-07 22:01:43,996:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-06-07 22:01:44,027:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-07 22:01:44,030:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-06-07 22:01:44,055:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-07 22:01:44,056:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-07 22:01:44,084:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-07 22:01:44,085:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-06-07 22:01:44,102:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-07 22:01:44,102:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-07 22:01:44,102:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-06-07 22:01:44,130:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-06-07 22:01:44,148:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-07 22:01:44,148:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-07 22:01:44,177:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-06-07 22:01:44,194:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-07 22:01:44,195:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-07 22:01:44,195:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-06-07 22:01:44,240:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-07 22:01:44,240:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-07 22:01:44,286:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-07 22:01:44,286:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-07 22:01:44,289:INFO:Preparing preprocessing pipeline...
2025-06-07 22:01:44,290:INFO:Set up simple imputation.
2025-06-07 22:01:44,292:INFO:Set up encoding of ordinal features.
2025-06-07 22:01:44,293:INFO:Set up encoding of categorical features.
2025-06-07 22:01:44,339:INFO:Finished creating preprocessing pipeline.
2025-06-07 22:01:44,350:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\JOSECA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'ingreso_mensual',
                                             'usa_app', 'usa_web',
                                             'satisfaccion', 'num_productos',
                                             'reclamos_ult_6m',
                                             'tasa_credito'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_feature...
                                                                         'data_type': dtype('O'),
                                                                         'mapping': F      0
M      1
NaN   -1
dtype: int64}],
                                                               return_df=True,
                                                               verbose=0))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['nivel_educacion', 'region'],
                                    transformer=OneHotEncoder(cols=['nivel_educacion',
                                                                    'region'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2025-06-07 22:01:44,350:INFO:Creating final display dataframe.
2025-06-07 22:01:44,474:INFO:Setup _display_container:                     Description             Value
0                    Session id               131
1                        Target  respondio_oferta
2                   Target type            Binary
3           Original data shape         (500, 13)
4        Transformed data shape         (500, 18)
5   Transformed train set shape         (350, 18)
6    Transformed test set shape         (150, 18)
7               Ignore features                 1
8              Numeric features                 8
9          Categorical features                 3
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator   StratifiedKFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment      MlflowLogger
21              Experiment Name  respuesta-autoML
22                          USI              0ddb
2025-06-07 22:01:44,524:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-07 22:01:44,524:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-07 22:01:44,570:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-07 22:01:44,570:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-07 22:01:44,570:INFO:Logging experiment in loggers
2025-06-07 22:01:45,015:INFO:SubProcess save_model() called ==================================
2025-06-07 22:01:45,035:INFO:Initializing save_model()
2025-06-07 22:01:45,035:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\JOSECA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'ingreso_mensual',
                                             'usa_app', 'usa_web',
                                             'satisfaccion', 'num_productos',
                                             'reclamos_ult_6m',
                                             'tasa_credito'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_feature...
                                                                         'data_type': dtype('O'),
                                                                         'mapping': F      0
M      1
NaN   -1
dtype: int64}],
                                                               return_df=True,
                                                               verbose=0))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['nivel_educacion', 'region'],
                                    transformer=OneHotEncoder(cols=['nivel_educacion',
                                                                    'region'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False), model_name=C:\Users\JOSECA~1\AppData\Local\Temp\tmprddi3apb\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\JOSECA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'ingreso_mensual',
                                             'usa_app', 'usa_web',
                                             'satisfaccion', 'num_productos',
                                             'reclamos_ult_6m',
                                             'tasa_credito'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_feature...
                                                                         'data_type': dtype('O'),
                                                                         'mapping': F      0
M      1
NaN   -1
dtype: int64}],
                                                               return_df=True,
                                                               verbose=0))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['nivel_educacion', 'region'],
                                    transformer=OneHotEncoder(cols=['nivel_educacion',
                                                                    'region'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False), verbose=False, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-06-07 22:01:45,035:INFO:Adding model into prep_pipe
2025-06-07 22:01:45,035:WARNING:Only Model saved as it was a pipeline.
2025-06-07 22:01:45,046:INFO:C:\Users\JOSECA~1\AppData\Local\Temp\tmprddi3apb\Transformation Pipeline.pkl saved in current working directory
2025-06-07 22:01:45,057:INFO:Pipeline(memory=FastMemory(location=C:\Users\JOSECA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'ingreso_mensual',
                                             'usa_app', 'usa_web',
                                             'satisfaccion', 'num_productos',
                                             'reclamos_ult_6m',
                                             'tasa_credito'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_feature...
                                                                         'data_type': dtype('O'),
                                                                         'mapping': F      0
M      1
NaN   -1
dtype: int64}],
                                                               return_df=True,
                                                               verbose=0))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['nivel_educacion', 'region'],
                                    transformer=OneHotEncoder(cols=['nivel_educacion',
                                                                    'region'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2025-06-07 22:01:45,057:INFO:save_model() successfully completed......................................
2025-06-07 22:01:45,145:INFO:SubProcess save_model() end ==================================
2025-06-07 22:01:45,160:INFO:setup() successfully completed in 0.87s...............
2025-06-07 22:01:45,160:INFO:Initializing compare_models()
2025-06-07 22:01:45,160:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000235C5235D10>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000235C5235D10>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-06-07 22:01:45,160:INFO:Checking exceptions
2025-06-07 22:01:45,163:INFO:Preparing display monitor
2025-06-07 22:01:45,165:INFO:Initializing Logistic Regression
2025-06-07 22:01:45,165:INFO:Total runtime is 0.0 minutes
2025-06-07 22:01:45,165:INFO:SubProcess create_model() called ==================================
2025-06-07 22:01:45,166:INFO:Initializing create_model()
2025-06-07 22:01:45,166:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000235C5235D10>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002358F90D710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-07 22:01:45,166:INFO:Checking exceptions
2025-06-07 22:01:45,166:INFO:Importing libraries
2025-06-07 22:01:45,166:INFO:Copying training dataset
2025-06-07 22:01:45,169:INFO:Defining folds
2025-06-07 22:01:45,169:INFO:Declaring metric variables
2025-06-07 22:01:45,169:INFO:Importing untrained model
2025-06-07 22:01:45,169:INFO:Logistic Regression Imported successfully
2025-06-07 22:01:45,169:INFO:Starting cross validation
2025-06-07 22:01:45,170:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-07 22:01:49,462:WARNING:C:\env\ml\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-07 22:01:49,482:WARNING:C:\env\ml\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-07 22:01:49,492:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:01:49,501:WARNING:C:\env\ml\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-07 22:01:49,508:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:01:49,521:WARNING:C:\env\ml\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-07 22:01:49,555:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:01:49,558:WARNING:C:\env\ml\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-07 22:01:49,558:WARNING:C:\env\ml\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-07 22:01:49,604:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:01:49,605:WARNING:C:\env\ml\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-07 22:01:49,635:WARNING:C:\env\ml\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-07 22:01:49,673:WARNING:C:\env\ml\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-07 22:01:49,677:WARNING:C:\env\ml\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-07 22:01:49,705:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:01:49,706:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:01:49,720:INFO:Calculating mean and std
2025-06-07 22:01:49,722:INFO:Creating metrics dataframe
2025-06-07 22:01:49,724:INFO:Uploading results into container
2025-06-07 22:01:49,725:INFO:Uploading model into container now
2025-06-07 22:01:49,726:INFO:_master_model_container: 1
2025-06-07 22:01:49,726:INFO:_display_container: 2
2025-06-07 22:01:49,726:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=131, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-06-07 22:01:49,726:INFO:create_model() successfully completed......................................
2025-06-07 22:01:49,832:INFO:SubProcess create_model() end ==================================
2025-06-07 22:01:49,832:INFO:Creating metrics dataframe
2025-06-07 22:01:49,834:INFO:Initializing K Neighbors Classifier
2025-06-07 22:01:49,834:INFO:Total runtime is 0.07781733671824137 minutes
2025-06-07 22:01:49,834:INFO:SubProcess create_model() called ==================================
2025-06-07 22:01:49,834:INFO:Initializing create_model()
2025-06-07 22:01:49,834:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000235C5235D10>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002358F90D710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-07 22:01:49,834:INFO:Checking exceptions
2025-06-07 22:01:49,834:INFO:Importing libraries
2025-06-07 22:01:49,834:INFO:Copying training dataset
2025-06-07 22:01:49,837:INFO:Defining folds
2025-06-07 22:01:49,837:INFO:Declaring metric variables
2025-06-07 22:01:49,837:INFO:Importing untrained model
2025-06-07 22:01:49,837:INFO:K Neighbors Classifier Imported successfully
2025-06-07 22:01:49,837:INFO:Starting cross validation
2025-06-07 22:01:49,839:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-07 22:01:54,360:INFO:Calculating mean and std
2025-06-07 22:01:54,362:INFO:Creating metrics dataframe
2025-06-07 22:01:54,363:INFO:Uploading results into container
2025-06-07 22:01:54,364:INFO:Uploading model into container now
2025-06-07 22:01:54,364:INFO:_master_model_container: 2
2025-06-07 22:01:54,364:INFO:_display_container: 2
2025-06-07 22:01:54,364:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-06-07 22:01:54,365:INFO:create_model() successfully completed......................................
2025-06-07 22:01:54,460:INFO:SubProcess create_model() end ==================================
2025-06-07 22:01:54,460:INFO:Creating metrics dataframe
2025-06-07 22:01:54,463:INFO:Initializing Naive Bayes
2025-06-07 22:01:54,463:INFO:Total runtime is 0.1549697796503703 minutes
2025-06-07 22:01:54,463:INFO:SubProcess create_model() called ==================================
2025-06-07 22:01:54,463:INFO:Initializing create_model()
2025-06-07 22:01:54,463:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000235C5235D10>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002358F90D710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-07 22:01:54,463:INFO:Checking exceptions
2025-06-07 22:01:54,464:INFO:Importing libraries
2025-06-07 22:01:54,464:INFO:Copying training dataset
2025-06-07 22:01:54,466:INFO:Defining folds
2025-06-07 22:01:54,466:INFO:Declaring metric variables
2025-06-07 22:01:54,466:INFO:Importing untrained model
2025-06-07 22:01:54,467:INFO:Naive Bayes Imported successfully
2025-06-07 22:01:54,467:INFO:Starting cross validation
2025-06-07 22:01:54,468:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-07 22:01:54,570:INFO:Calculating mean and std
2025-06-07 22:01:54,570:INFO:Creating metrics dataframe
2025-06-07 22:01:54,572:INFO:Uploading results into container
2025-06-07 22:01:54,572:INFO:Uploading model into container now
2025-06-07 22:01:54,572:INFO:_master_model_container: 3
2025-06-07 22:01:54,572:INFO:_display_container: 2
2025-06-07 22:01:54,572:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-06-07 22:01:54,573:INFO:create_model() successfully completed......................................
2025-06-07 22:01:54,663:INFO:SubProcess create_model() end ==================================
2025-06-07 22:01:54,663:INFO:Creating metrics dataframe
2025-06-07 22:01:54,665:INFO:Initializing Decision Tree Classifier
2025-06-07 22:01:54,665:INFO:Total runtime is 0.1583227276802063 minutes
2025-06-07 22:01:54,665:INFO:SubProcess create_model() called ==================================
2025-06-07 22:01:54,665:INFO:Initializing create_model()
2025-06-07 22:01:54,665:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000235C5235D10>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002358F90D710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-07 22:01:54,665:INFO:Checking exceptions
2025-06-07 22:01:54,665:INFO:Importing libraries
2025-06-07 22:01:54,665:INFO:Copying training dataset
2025-06-07 22:01:54,668:INFO:Defining folds
2025-06-07 22:01:54,668:INFO:Declaring metric variables
2025-06-07 22:01:54,668:INFO:Importing untrained model
2025-06-07 22:01:54,668:INFO:Decision Tree Classifier Imported successfully
2025-06-07 22:01:54,668:INFO:Starting cross validation
2025-06-07 22:01:54,669:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-07 22:01:54,770:INFO:Calculating mean and std
2025-06-07 22:01:54,771:INFO:Creating metrics dataframe
2025-06-07 22:01:54,773:INFO:Uploading results into container
2025-06-07 22:01:54,773:INFO:Uploading model into container now
2025-06-07 22:01:54,773:INFO:_master_model_container: 4
2025-06-07 22:01:54,773:INFO:_display_container: 2
2025-06-07 22:01:54,774:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=131, splitter='best')
2025-06-07 22:01:54,774:INFO:create_model() successfully completed......................................
2025-06-07 22:01:54,865:INFO:SubProcess create_model() end ==================================
2025-06-07 22:01:54,865:INFO:Creating metrics dataframe
2025-06-07 22:01:54,867:INFO:Initializing SVM - Linear Kernel
2025-06-07 22:01:54,867:INFO:Total runtime is 0.16170305013656616 minutes
2025-06-07 22:01:54,867:INFO:SubProcess create_model() called ==================================
2025-06-07 22:01:54,867:INFO:Initializing create_model()
2025-06-07 22:01:54,867:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000235C5235D10>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002358F90D710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-07 22:01:54,867:INFO:Checking exceptions
2025-06-07 22:01:54,867:INFO:Importing libraries
2025-06-07 22:01:54,867:INFO:Copying training dataset
2025-06-07 22:01:54,870:INFO:Defining folds
2025-06-07 22:01:54,870:INFO:Declaring metric variables
2025-06-07 22:01:54,870:INFO:Importing untrained model
2025-06-07 22:01:54,870:INFO:SVM - Linear Kernel Imported successfully
2025-06-07 22:01:54,871:INFO:Starting cross validation
2025-06-07 22:01:54,873:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-07 22:01:54,955:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:01:54,957:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:01:54,958:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:01:54,966:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:01:54,974:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:01:54,978:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:01:54,996:INFO:Calculating mean and std
2025-06-07 22:01:54,996:INFO:Creating metrics dataframe
2025-06-07 22:01:54,998:INFO:Uploading results into container
2025-06-07 22:01:54,998:INFO:Uploading model into container now
2025-06-07 22:01:54,998:INFO:_master_model_container: 5
2025-06-07 22:01:54,998:INFO:_display_container: 2
2025-06-07 22:01:54,999:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=131, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-06-07 22:01:54,999:INFO:create_model() successfully completed......................................
2025-06-07 22:01:55,091:INFO:SubProcess create_model() end ==================================
2025-06-07 22:01:55,091:INFO:Creating metrics dataframe
2025-06-07 22:01:55,093:INFO:Initializing Ridge Classifier
2025-06-07 22:01:55,093:INFO:Total runtime is 0.1654576579729716 minutes
2025-06-07 22:01:55,094:INFO:SubProcess create_model() called ==================================
2025-06-07 22:01:55,094:INFO:Initializing create_model()
2025-06-07 22:01:55,094:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000235C5235D10>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002358F90D710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-07 22:01:55,094:INFO:Checking exceptions
2025-06-07 22:01:55,094:INFO:Importing libraries
2025-06-07 22:01:55,094:INFO:Copying training dataset
2025-06-07 22:01:55,097:INFO:Defining folds
2025-06-07 22:01:55,097:INFO:Declaring metric variables
2025-06-07 22:01:55,097:INFO:Importing untrained model
2025-06-07 22:01:55,098:INFO:Ridge Classifier Imported successfully
2025-06-07 22:01:55,098:INFO:Starting cross validation
2025-06-07 22:01:55,099:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-07 22:01:55,187:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:01:55,188:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:01:55,197:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:01:55,197:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:01:55,200:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:01:55,204:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:01:55,204:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:01:55,213:INFO:Calculating mean and std
2025-06-07 22:01:55,214:INFO:Creating metrics dataframe
2025-06-07 22:01:55,215:INFO:Uploading results into container
2025-06-07 22:01:55,215:INFO:Uploading model into container now
2025-06-07 22:01:55,216:INFO:_master_model_container: 6
2025-06-07 22:01:55,216:INFO:_display_container: 2
2025-06-07 22:01:55,216:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=131, solver='auto',
                tol=0.0001)
2025-06-07 22:01:55,216:INFO:create_model() successfully completed......................................
2025-06-07 22:01:55,316:INFO:SubProcess create_model() end ==================================
2025-06-07 22:01:55,316:INFO:Creating metrics dataframe
2025-06-07 22:01:55,318:INFO:Initializing Random Forest Classifier
2025-06-07 22:01:55,319:INFO:Total runtime is 0.16922181844711304 minutes
2025-06-07 22:01:55,319:INFO:SubProcess create_model() called ==================================
2025-06-07 22:01:55,319:INFO:Initializing create_model()
2025-06-07 22:01:55,319:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000235C5235D10>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002358F90D710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-07 22:01:55,319:INFO:Checking exceptions
2025-06-07 22:01:55,319:INFO:Importing libraries
2025-06-07 22:01:55,319:INFO:Copying training dataset
2025-06-07 22:01:55,323:INFO:Defining folds
2025-06-07 22:01:55,323:INFO:Declaring metric variables
2025-06-07 22:01:55,324:INFO:Importing untrained model
2025-06-07 22:01:55,324:INFO:Random Forest Classifier Imported successfully
2025-06-07 22:01:55,324:INFO:Starting cross validation
2025-06-07 22:01:55,326:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-07 22:01:55,669:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:01:55,678:INFO:Calculating mean and std
2025-06-07 22:01:55,679:INFO:Creating metrics dataframe
2025-06-07 22:01:55,681:INFO:Uploading results into container
2025-06-07 22:01:55,681:INFO:Uploading model into container now
2025-06-07 22:01:55,681:INFO:_master_model_container: 7
2025-06-07 22:01:55,682:INFO:_display_container: 2
2025-06-07 22:01:55,682:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=131, verbose=0,
                       warm_start=False)
2025-06-07 22:01:55,682:INFO:create_model() successfully completed......................................
2025-06-07 22:01:55,784:INFO:SubProcess create_model() end ==================================
2025-06-07 22:01:55,784:INFO:Creating metrics dataframe
2025-06-07 22:01:55,785:INFO:Initializing Quadratic Discriminant Analysis
2025-06-07 22:01:55,786:INFO:Total runtime is 0.17700055837631226 minutes
2025-06-07 22:01:55,786:INFO:SubProcess create_model() called ==================================
2025-06-07 22:01:55,786:INFO:Initializing create_model()
2025-06-07 22:01:55,786:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000235C5235D10>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002358F90D710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-07 22:01:55,786:INFO:Checking exceptions
2025-06-07 22:01:55,786:INFO:Importing libraries
2025-06-07 22:01:55,786:INFO:Copying training dataset
2025-06-07 22:01:55,789:INFO:Defining folds
2025-06-07 22:01:55,789:INFO:Declaring metric variables
2025-06-07 22:01:55,789:INFO:Importing untrained model
2025-06-07 22:01:55,789:INFO:Quadratic Discriminant Analysis Imported successfully
2025-06-07 22:01:55,790:INFO:Starting cross validation
2025-06-07 22:01:55,791:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-07 22:01:55,849:WARNING:C:\env\ml\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-06-07 22:01:55,850:WARNING:C:\env\ml\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-06-07 22:01:55,852:WARNING:C:\env\ml\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-06-07 22:01:55,852:WARNING:C:\env\ml\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-06-07 22:01:55,860:WARNING:C:\env\ml\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-06-07 22:01:55,864:WARNING:C:\env\ml\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-06-07 22:01:55,867:WARNING:C:\env\ml\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-06-07 22:01:55,867:WARNING:C:\env\ml\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-06-07 22:01:55,871:WARNING:C:\env\ml\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-06-07 22:01:55,904:INFO:Calculating mean and std
2025-06-07 22:01:55,905:INFO:Creating metrics dataframe
2025-06-07 22:01:55,907:INFO:Uploading results into container
2025-06-07 22:01:55,907:INFO:Uploading model into container now
2025-06-07 22:01:55,907:INFO:_master_model_container: 8
2025-06-07 22:01:55,907:INFO:_display_container: 2
2025-06-07 22:01:55,908:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-06-07 22:01:55,908:INFO:create_model() successfully completed......................................
2025-06-07 22:01:56,000:INFO:SubProcess create_model() end ==================================
2025-06-07 22:01:56,000:INFO:Creating metrics dataframe
2025-06-07 22:01:56,002:INFO:Initializing Ada Boost Classifier
2025-06-07 22:01:56,002:INFO:Total runtime is 0.1806203285853068 minutes
2025-06-07 22:01:56,002:INFO:SubProcess create_model() called ==================================
2025-06-07 22:01:56,002:INFO:Initializing create_model()
2025-06-07 22:01:56,002:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000235C5235D10>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002358F90D710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-07 22:01:56,002:INFO:Checking exceptions
2025-06-07 22:01:56,002:INFO:Importing libraries
2025-06-07 22:01:56,002:INFO:Copying training dataset
2025-06-07 22:01:56,005:INFO:Defining folds
2025-06-07 22:01:56,005:INFO:Declaring metric variables
2025-06-07 22:01:56,005:INFO:Importing untrained model
2025-06-07 22:01:56,006:INFO:Ada Boost Classifier Imported successfully
2025-06-07 22:01:56,006:INFO:Starting cross validation
2025-06-07 22:01:56,007:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-07 22:01:56,062:WARNING:C:\env\ml\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-06-07 22:01:56,062:WARNING:C:\env\ml\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-06-07 22:01:56,062:WARNING:C:\env\ml\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-06-07 22:01:56,073:WARNING:C:\env\ml\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-06-07 22:01:56,076:WARNING:C:\env\ml\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-06-07 22:01:56,078:WARNING:C:\env\ml\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-06-07 22:01:56,080:WARNING:C:\env\ml\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-06-07 22:01:56,082:WARNING:C:\env\ml\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-06-07 22:01:56,083:WARNING:C:\env\ml\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-06-07 22:01:56,215:INFO:Calculating mean and std
2025-06-07 22:01:56,216:INFO:Creating metrics dataframe
2025-06-07 22:01:56,218:INFO:Uploading results into container
2025-06-07 22:01:56,218:INFO:Uploading model into container now
2025-06-07 22:01:56,219:INFO:_master_model_container: 9
2025-06-07 22:01:56,219:INFO:_display_container: 2
2025-06-07 22:01:56,219:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=131)
2025-06-07 22:01:56,219:INFO:create_model() successfully completed......................................
2025-06-07 22:01:56,314:INFO:SubProcess create_model() end ==================================
2025-06-07 22:01:56,314:INFO:Creating metrics dataframe
2025-06-07 22:01:56,316:INFO:Initializing Gradient Boosting Classifier
2025-06-07 22:01:56,316:INFO:Total runtime is 0.18583931922912597 minutes
2025-06-07 22:01:56,316:INFO:SubProcess create_model() called ==================================
2025-06-07 22:01:56,316:INFO:Initializing create_model()
2025-06-07 22:01:56,316:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000235C5235D10>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002358F90D710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-07 22:01:56,316:INFO:Checking exceptions
2025-06-07 22:01:56,316:INFO:Importing libraries
2025-06-07 22:01:56,316:INFO:Copying training dataset
2025-06-07 22:01:56,319:INFO:Defining folds
2025-06-07 22:01:56,319:INFO:Declaring metric variables
2025-06-07 22:01:56,320:INFO:Importing untrained model
2025-06-07 22:01:56,320:INFO:Gradient Boosting Classifier Imported successfully
2025-06-07 22:01:56,320:INFO:Starting cross validation
2025-06-07 22:01:56,321:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-07 22:01:56,523:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:01:56,561:INFO:Calculating mean and std
2025-06-07 22:01:56,562:INFO:Creating metrics dataframe
2025-06-07 22:01:56,564:INFO:Uploading results into container
2025-06-07 22:01:56,564:INFO:Uploading model into container now
2025-06-07 22:01:56,565:INFO:_master_model_container: 10
2025-06-07 22:01:56,565:INFO:_display_container: 2
2025-06-07 22:01:56,565:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=131, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-06-07 22:01:56,565:INFO:create_model() successfully completed......................................
2025-06-07 22:01:56,664:INFO:SubProcess create_model() end ==================================
2025-06-07 22:01:56,664:INFO:Creating metrics dataframe
2025-06-07 22:01:56,666:INFO:Initializing Linear Discriminant Analysis
2025-06-07 22:01:56,666:INFO:Total runtime is 0.19167739550272622 minutes
2025-06-07 22:01:56,666:INFO:SubProcess create_model() called ==================================
2025-06-07 22:01:56,667:INFO:Initializing create_model()
2025-06-07 22:01:56,667:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000235C5235D10>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002358F90D710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-07 22:01:56,667:INFO:Checking exceptions
2025-06-07 22:01:56,667:INFO:Importing libraries
2025-06-07 22:01:56,667:INFO:Copying training dataset
2025-06-07 22:01:56,670:INFO:Defining folds
2025-06-07 22:01:56,670:INFO:Declaring metric variables
2025-06-07 22:01:56,670:INFO:Importing untrained model
2025-06-07 22:01:56,670:INFO:Linear Discriminant Analysis Imported successfully
2025-06-07 22:01:56,671:INFO:Starting cross validation
2025-06-07 22:01:56,672:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-07 22:01:56,757:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:01:56,770:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:01:56,774:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:01:56,779:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:01:56,786:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:01:56,794:INFO:Calculating mean and std
2025-06-07 22:01:56,795:INFO:Creating metrics dataframe
2025-06-07 22:01:56,796:INFO:Uploading results into container
2025-06-07 22:01:56,797:INFO:Uploading model into container now
2025-06-07 22:01:56,797:INFO:_master_model_container: 11
2025-06-07 22:01:56,797:INFO:_display_container: 2
2025-06-07 22:01:56,797:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-06-07 22:01:56,797:INFO:create_model() successfully completed......................................
2025-06-07 22:01:56,896:INFO:SubProcess create_model() end ==================================
2025-06-07 22:01:56,896:INFO:Creating metrics dataframe
2025-06-07 22:01:56,898:INFO:Initializing Extra Trees Classifier
2025-06-07 22:01:56,898:INFO:Total runtime is 0.1955428957939148 minutes
2025-06-07 22:01:56,898:INFO:SubProcess create_model() called ==================================
2025-06-07 22:01:56,898:INFO:Initializing create_model()
2025-06-07 22:01:56,898:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000235C5235D10>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002358F90D710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-07 22:01:56,899:INFO:Checking exceptions
2025-06-07 22:01:56,899:INFO:Importing libraries
2025-06-07 22:01:56,899:INFO:Copying training dataset
2025-06-07 22:01:56,902:INFO:Defining folds
2025-06-07 22:01:56,902:INFO:Declaring metric variables
2025-06-07 22:01:56,902:INFO:Importing untrained model
2025-06-07 22:01:56,903:INFO:Extra Trees Classifier Imported successfully
2025-06-07 22:01:56,903:INFO:Starting cross validation
2025-06-07 22:01:56,904:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-07 22:01:57,234:INFO:Calculating mean and std
2025-06-07 22:01:57,235:INFO:Creating metrics dataframe
2025-06-07 22:01:57,236:INFO:Uploading results into container
2025-06-07 22:01:57,237:INFO:Uploading model into container now
2025-06-07 22:01:57,237:INFO:_master_model_container: 12
2025-06-07 22:01:57,237:INFO:_display_container: 2
2025-06-07 22:01:57,237:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=131, verbose=0,
                     warm_start=False)
2025-06-07 22:01:57,237:INFO:create_model() successfully completed......................................
2025-06-07 22:01:57,334:INFO:SubProcess create_model() end ==================================
2025-06-07 22:01:57,334:INFO:Creating metrics dataframe
2025-06-07 22:01:57,336:INFO:Initializing Light Gradient Boosting Machine
2025-06-07 22:01:57,336:INFO:Total runtime is 0.2028433283170064 minutes
2025-06-07 22:01:57,336:INFO:SubProcess create_model() called ==================================
2025-06-07 22:01:57,336:INFO:Initializing create_model()
2025-06-07 22:01:57,336:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000235C5235D10>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002358F90D710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-07 22:01:57,336:INFO:Checking exceptions
2025-06-07 22:01:57,336:INFO:Importing libraries
2025-06-07 22:01:57,336:INFO:Copying training dataset
2025-06-07 22:01:57,339:INFO:Defining folds
2025-06-07 22:01:57,339:INFO:Declaring metric variables
2025-06-07 22:01:57,339:INFO:Importing untrained model
2025-06-07 22:01:57,340:INFO:Light Gradient Boosting Machine Imported successfully
2025-06-07 22:01:57,340:INFO:Starting cross validation
2025-06-07 22:01:57,341:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-07 22:01:57,994:INFO:Calculating mean and std
2025-06-07 22:01:57,994:INFO:Creating metrics dataframe
2025-06-07 22:01:57,996:INFO:Uploading results into container
2025-06-07 22:01:57,997:INFO:Uploading model into container now
2025-06-07 22:01:57,997:INFO:_master_model_container: 13
2025-06-07 22:01:57,997:INFO:_display_container: 2
2025-06-07 22:01:57,998:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=131, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-06-07 22:01:57,998:INFO:create_model() successfully completed......................................
2025-06-07 22:01:58,115:INFO:SubProcess create_model() end ==================================
2025-06-07 22:01:58,115:INFO:Creating metrics dataframe
2025-06-07 22:01:58,118:INFO:Initializing Dummy Classifier
2025-06-07 22:01:58,118:INFO:Total runtime is 0.21587326924006142 minutes
2025-06-07 22:01:58,118:INFO:SubProcess create_model() called ==================================
2025-06-07 22:01:58,118:INFO:Initializing create_model()
2025-06-07 22:01:58,118:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000235C5235D10>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002358F90D710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-07 22:01:58,118:INFO:Checking exceptions
2025-06-07 22:01:58,118:INFO:Importing libraries
2025-06-07 22:01:58,118:INFO:Copying training dataset
2025-06-07 22:01:58,122:INFO:Defining folds
2025-06-07 22:01:58,122:INFO:Declaring metric variables
2025-06-07 22:01:58,122:INFO:Importing untrained model
2025-06-07 22:01:58,122:INFO:Dummy Classifier Imported successfully
2025-06-07 22:01:58,123:INFO:Starting cross validation
2025-06-07 22:01:58,124:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-07 22:01:58,212:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:01:58,217:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:01:58,219:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:01:58,224:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:01:58,226:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:01:58,229:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:01:58,231:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:01:58,233:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:01:58,235:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:01:58,237:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:01:58,247:INFO:Calculating mean and std
2025-06-07 22:01:58,248:INFO:Creating metrics dataframe
2025-06-07 22:01:58,249:INFO:Uploading results into container
2025-06-07 22:01:58,250:INFO:Uploading model into container now
2025-06-07 22:01:58,250:INFO:_master_model_container: 14
2025-06-07 22:01:58,250:INFO:_display_container: 2
2025-06-07 22:01:58,250:INFO:DummyClassifier(constant=None, random_state=131, strategy='prior')
2025-06-07 22:01:58,250:INFO:create_model() successfully completed......................................
2025-06-07 22:01:58,346:INFO:SubProcess create_model() end ==================================
2025-06-07 22:01:58,346:INFO:Creating metrics dataframe
2025-06-07 22:01:58,350:WARNING:C:\env\ml\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-06-07 22:01:58,351:INFO:Initializing create_model()
2025-06-07 22:01:58,351:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000235C5235D10>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=131, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-07 22:01:58,352:INFO:Checking exceptions
2025-06-07 22:01:58,352:INFO:Importing libraries
2025-06-07 22:01:58,352:INFO:Copying training dataset
2025-06-07 22:01:58,355:INFO:Defining folds
2025-06-07 22:01:58,355:INFO:Declaring metric variables
2025-06-07 22:01:58,355:INFO:Importing untrained model
2025-06-07 22:01:58,355:INFO:Declaring custom model
2025-06-07 22:01:58,355:INFO:Random Forest Classifier Imported successfully
2025-06-07 22:01:58,356:INFO:Cross validation set to False
2025-06-07 22:01:58,356:INFO:Fitting Model
2025-06-07 22:01:58,500:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=131, verbose=0,
                       warm_start=False)
2025-06-07 22:01:58,500:INFO:create_model() successfully completed......................................
2025-06-07 22:01:58,598:INFO:Creating Dashboard logs
2025-06-07 22:01:58,599:INFO:Model: Random Forest Classifier
2025-06-07 22:01:58,655:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 131, 'verbose': 0, 'warm_start': False}
2025-06-07 22:01:58,781:INFO:Initializing predict_model()
2025-06-07 22:01:58,781:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000235C5235D10>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=131, verbose=0,
                       warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000023591143EC0>)
2025-06-07 22:01:58,781:INFO:Checking exceptions
2025-06-07 22:01:58,781:INFO:Preloading libraries
2025-06-07 22:01:59,030:INFO:SubProcess plot_model() called ==================================
2025-06-07 22:01:59,031:INFO:Initializing plot_model()
2025-06-07 22:01:59,031:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000235C5235D10>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=131, verbose=0,
                       warm_start=False), plot=auc, scale=1, save=C:\Users\JOSECA~1\AppData\Local\Temp\tmpm_jamt9a, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=False, display=None, display_format=None)
2025-06-07 22:01:59,031:INFO:Checking exceptions
2025-06-07 22:01:59,050:INFO:Preloading libraries
2025-06-07 22:01:59,058:INFO:Copying training dataset
2025-06-07 22:01:59,058:INFO:Plot type: auc
2025-06-07 22:01:59,426:INFO:Fitting Model
2025-06-07 22:01:59,428:WARNING:C:\env\ml\Lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names
  warnings.warn(

2025-06-07 22:01:59,429:INFO:Scoring test/hold-out set
2025-06-07 22:01:59,502:INFO:Saving 'C:\Users\JOSECA~1\AppData\Local\Temp\tmpm_jamt9a\AUC.png'
2025-06-07 22:01:59,638:INFO:Visual Rendered Successfully
2025-06-07 22:01:59,779:INFO:plot_model() successfully completed......................................
2025-06-07 22:01:59,783:INFO:Initializing plot_model()
2025-06-07 22:01:59,783:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000235C5235D10>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=131, verbose=0,
                       warm_start=False), plot=confusion_matrix, scale=1, save=C:\Users\JOSECA~1\AppData\Local\Temp\tmpm_jamt9a, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=False, display=None, display_format=None)
2025-06-07 22:01:59,783:INFO:Checking exceptions
2025-06-07 22:01:59,802:INFO:Preloading libraries
2025-06-07 22:01:59,809:INFO:Copying training dataset
2025-06-07 22:01:59,809:INFO:Plot type: confusion_matrix
2025-06-07 22:02:00,065:INFO:Fitting Model
2025-06-07 22:02:00,065:WARNING:C:\env\ml\Lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names
  warnings.warn(

2025-06-07 22:02:00,066:INFO:Scoring test/hold-out set
2025-06-07 22:02:00,132:INFO:Saving 'C:\Users\JOSECA~1\AppData\Local\Temp\tmpm_jamt9a\Confusion Matrix.png'
2025-06-07 22:02:00,197:INFO:Visual Rendered Successfully
2025-06-07 22:02:00,318:INFO:plot_model() successfully completed......................................
2025-06-07 22:02:00,323:INFO:Initializing plot_model()
2025-06-07 22:02:00,323:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000235C5235D10>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=131, verbose=0,
                       warm_start=False), plot=feature, scale=1, save=C:\Users\JOSECA~1\AppData\Local\Temp\tmpm_jamt9a, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=False, display=None, display_format=None)
2025-06-07 22:02:00,323:INFO:Checking exceptions
2025-06-07 22:02:00,342:INFO:Preloading libraries
2025-06-07 22:02:00,347:INFO:Copying training dataset
2025-06-07 22:02:00,347:INFO:Plot type: feature
2025-06-07 22:02:00,348:WARNING:No coef_ found. Trying feature_importances_
2025-06-07 22:02:00,517:INFO:Saving 'C:\Users\JOSECA~1\AppData\Local\Temp\tmpm_jamt9a\Feature Importance.png'
2025-06-07 22:02:00,627:INFO:Visual Rendered Successfully
2025-06-07 22:02:00,737:INFO:plot_model() successfully completed......................................
2025-06-07 22:02:00,741:INFO:SubProcess plot_model() end ==================================
2025-06-07 22:02:00,744:WARNING:C:\env\ml\Lib\site-packages\_distutils_hack\__init__.py:33: UserWarning: Setuptools is replacing distutils.
  warnings.warn("Setuptools is replacing distutils.")

2025-06-07 22:02:02,183:INFO:Creating Dashboard logs
2025-06-07 22:02:02,183:INFO:Model: Dummy Classifier
2025-06-07 22:02:02,224:INFO:Logged params: {'constant': None, 'random_state': 131, 'strategy': 'prior'}
2025-06-07 22:02:02,467:INFO:Creating Dashboard logs
2025-06-07 22:02:02,467:INFO:Model: Ridge Classifier
2025-06-07 22:02:02,511:INFO:Logged params: {'alpha': 1.0, 'class_weight': None, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': 131, 'solver': 'auto', 'tol': 0.0001}
2025-06-07 22:02:02,769:INFO:Creating Dashboard logs
2025-06-07 22:02:02,769:INFO:Model: Logistic Regression
2025-06-07 22:02:02,811:INFO:Logged params: {'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': 131, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}
2025-06-07 22:02:03,081:INFO:Creating Dashboard logs
2025-06-07 22:02:03,081:INFO:Model: Linear Discriminant Analysis
2025-06-07 22:02:03,125:INFO:Logged params: {'covariance_estimator': None, 'n_components': None, 'priors': None, 'shrinkage': None, 'solver': 'svd', 'store_covariance': False, 'tol': 0.0001}
2025-06-07 22:02:03,377:INFO:Creating Dashboard logs
2025-06-07 22:02:03,377:INFO:Model: Extra Trees Classifier
2025-06-07 22:02:03,422:INFO:Logged params: {'bootstrap': False, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 131, 'verbose': 0, 'warm_start': False}
2025-06-07 22:02:03,709:INFO:Creating Dashboard logs
2025-06-07 22:02:03,709:INFO:Model: K Neighbors Classifier
2025-06-07 22:02:03,770:INFO:Logged params: {'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 5, 'p': 2, 'weights': 'uniform'}
2025-06-07 22:02:04,079:INFO:Creating Dashboard logs
2025-06-07 22:02:04,079:INFO:Model: Decision Tree Classifier
2025-06-07 22:02:04,130:INFO:Logged params: {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'random_state': 131, 'splitter': 'best'}
2025-06-07 22:02:04,425:INFO:Creating Dashboard logs
2025-06-07 22:02:04,425:INFO:Model: Gradient Boosting Classifier
2025-06-07 22:02:04,475:INFO:Logged params: {'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'log_loss', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 131, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2025-06-07 22:02:04,746:INFO:Creating Dashboard logs
2025-06-07 22:02:04,746:INFO:Model: Ada Boost Classifier
2025-06-07 22:02:04,790:INFO:Logged params: {'algorithm': 'SAMME.R', 'estimator': None, 'learning_rate': 1.0, 'n_estimators': 50, 'random_state': 131}
2025-06-07 22:02:05,062:INFO:Creating Dashboard logs
2025-06-07 22:02:05,062:INFO:Model: Naive Bayes
2025-06-07 22:02:05,108:INFO:Logged params: {'priors': None, 'var_smoothing': 1e-09}
2025-06-07 22:02:05,399:INFO:Creating Dashboard logs
2025-06-07 22:02:05,399:INFO:Model: Light Gradient Boosting Machine
2025-06-07 22:02:05,455:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 131, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2025-06-07 22:02:05,774:INFO:Creating Dashboard logs
2025-06-07 22:02:05,775:INFO:Model: SVM - Linear Kernel
2025-06-07 22:02:05,832:INFO:Logged params: {'alpha': 0.0001, 'average': False, 'class_weight': None, 'early_stopping': False, 'epsilon': 0.1, 'eta0': 0.001, 'fit_intercept': True, 'l1_ratio': 0.15, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1000, 'n_iter_no_change': 5, 'n_jobs': -1, 'penalty': 'l2', 'power_t': 0.5, 'random_state': 131, 'shuffle': True, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2025-06-07 22:02:06,168:INFO:Creating Dashboard logs
2025-06-07 22:02:06,168:INFO:Model: Quadratic Discriminant Analysis
2025-06-07 22:02:06,213:INFO:Logged params: {'priors': None, 'reg_param': 0.0, 'store_covariance': False, 'tol': 0.0001}
2025-06-07 22:02:06,461:INFO:_master_model_container: 14
2025-06-07 22:02:06,461:INFO:_display_container: 2
2025-06-07 22:02:06,462:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=131, verbose=0,
                       warm_start=False)
2025-06-07 22:02:06,462:INFO:compare_models() successfully completed......................................
2025-06-07 22:02:06,462:INFO:Initializing tune_model()
2025-06-07 22:02:06,462:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000235C5235D10>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=131, verbose=0,
                       warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2025-06-07 22:02:06,462:INFO:Checking exceptions
2025-06-07 22:02:06,465:INFO:Copying training dataset
2025-06-07 22:02:06,467:INFO:Checking base model
2025-06-07 22:02:06,467:INFO:Base model : Random Forest Classifier
2025-06-07 22:02:06,467:INFO:Declaring metric variables
2025-06-07 22:02:06,467:INFO:Defining Hyperparameters
2025-06-07 22:02:06,565:INFO:Tuning with n_jobs=-1
2025-06-07 22:02:06,565:INFO:Initializing RandomizedSearchCV
2025-06-07 22:02:10,105:INFO:best_params: {'actual_estimator__n_estimators': 290, 'actual_estimator__min_samples_split': 10, 'actual_estimator__min_samples_leaf': 5, 'actual_estimator__min_impurity_decrease': 0.2, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 7, 'actual_estimator__criterion': 'gini', 'actual_estimator__class_weight': 'balanced', 'actual_estimator__bootstrap': False}
2025-06-07 22:02:10,105:INFO:Hyperparameter search completed
2025-06-07 22:02:10,106:INFO:SubProcess create_model() called ==================================
2025-06-07 22:02:10,106:INFO:Initializing create_model()
2025-06-07 22:02:10,106:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000235C5235D10>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=131, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002358F8F2E50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_estimators': 290, 'min_samples_split': 10, 'min_samples_leaf': 5, 'min_impurity_decrease': 0.2, 'max_features': 1.0, 'max_depth': 7, 'criterion': 'gini', 'class_weight': 'balanced', 'bootstrap': False})
2025-06-07 22:02:10,106:INFO:Checking exceptions
2025-06-07 22:02:10,106:INFO:Importing libraries
2025-06-07 22:02:10,106:INFO:Copying training dataset
2025-06-07 22:02:10,109:INFO:Defining folds
2025-06-07 22:02:10,109:INFO:Declaring metric variables
2025-06-07 22:02:10,109:INFO:Importing untrained model
2025-06-07 22:02:10,109:INFO:Declaring custom model
2025-06-07 22:02:10,110:INFO:Random Forest Classifier Imported successfully
2025-06-07 22:02:10,110:INFO:Starting cross validation
2025-06-07 22:02:10,111:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-07 22:02:10,594:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:02:10,596:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:02:10,604:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:02:10,606:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:02:10,610:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:02:10,612:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:02:10,633:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:02:10,638:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:02:10,646:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:02:10,652:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:02:10,659:INFO:Calculating mean and std
2025-06-07 22:02:10,660:INFO:Creating metrics dataframe
2025-06-07 22:02:10,661:INFO:Finalizing model
2025-06-07 22:02:10,902:INFO:Uploading results into container
2025-06-07 22:02:10,903:INFO:Uploading model into container now
2025-06-07 22:02:10,903:INFO:_master_model_container: 15
2025-06-07 22:02:10,903:INFO:_display_container: 3
2025-06-07 22:02:10,904:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight='balanced',
                       criterion='gini', max_depth=7, max_features=1.0,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.2, min_samples_leaf=5,
                       min_samples_split=10, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=290, n_jobs=-1,
                       oob_score=False, random_state=131, verbose=0,
                       warm_start=False)
2025-06-07 22:02:10,904:INFO:create_model() successfully completed......................................
2025-06-07 22:02:11,002:INFO:SubProcess create_model() end ==================================
2025-06-07 22:02:11,002:INFO:choose_better activated
2025-06-07 22:02:11,003:INFO:SubProcess create_model() called ==================================
2025-06-07 22:02:11,003:INFO:Initializing create_model()
2025-06-07 22:02:11,003:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000235C5235D10>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=131, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-07 22:02:11,003:INFO:Checking exceptions
2025-06-07 22:02:11,004:INFO:Importing libraries
2025-06-07 22:02:11,004:INFO:Copying training dataset
2025-06-07 22:02:11,006:INFO:Defining folds
2025-06-07 22:02:11,006:INFO:Declaring metric variables
2025-06-07 22:02:11,006:INFO:Importing untrained model
2025-06-07 22:02:11,006:INFO:Declaring custom model
2025-06-07 22:02:11,007:INFO:Random Forest Classifier Imported successfully
2025-06-07 22:02:11,007:INFO:Starting cross validation
2025-06-07 22:02:11,008:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-07 22:02:11,318:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:02:11,345:INFO:Calculating mean and std
2025-06-07 22:02:11,345:INFO:Creating metrics dataframe
2025-06-07 22:02:11,347:INFO:Finalizing model
2025-06-07 22:02:11,480:INFO:Uploading results into container
2025-06-07 22:02:11,481:INFO:Uploading model into container now
2025-06-07 22:02:11,481:INFO:_master_model_container: 16
2025-06-07 22:02:11,481:INFO:_display_container: 4
2025-06-07 22:02:11,482:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=131, verbose=0,
                       warm_start=False)
2025-06-07 22:02:11,482:INFO:create_model() successfully completed......................................
2025-06-07 22:02:11,578:INFO:SubProcess create_model() end ==================================
2025-06-07 22:02:11,579:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=131, verbose=0,
                       warm_start=False) result for Accuracy is 0.7114
2025-06-07 22:02:11,579:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight='balanced',
                       criterion='gini', max_depth=7, max_features=1.0,
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.2, min_samples_leaf=5,
                       min_samples_split=10, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=290, n_jobs=-1,
                       oob_score=False, random_state=131, verbose=0,
                       warm_start=False) result for Accuracy is 0.7086
2025-06-07 22:02:11,580:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=131, verbose=0,
                       warm_start=False) is best model
2025-06-07 22:02:11,580:INFO:choose_better completed
2025-06-07 22:02:11,580:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-06-07 22:02:11,580:INFO:Creating Dashboard logs
2025-06-07 22:02:11,580:INFO:Model: Random Forest Classifier
2025-06-07 22:02:11,634:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 131, 'verbose': 0, 'warm_start': False}
2025-06-07 22:02:11,757:INFO:Initializing predict_model()
2025-06-07 22:02:11,757:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000235C5235D10>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=131, verbose=0,
                       warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000023590D822A0>)
2025-06-07 22:02:11,757:INFO:Checking exceptions
2025-06-07 22:02:11,757:INFO:Preloading libraries
2025-06-07 22:02:11,993:INFO:SubProcess plot_model() called ==================================
2025-06-07 22:02:11,993:INFO:Initializing plot_model()
2025-06-07 22:02:11,993:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000235C5235D10>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=131, verbose=0,
                       warm_start=False), plot=auc, scale=1, save=C:\Users\JOSECA~1\AppData\Local\Temp\tmpir97p934, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=False, display=None, display_format=None)
2025-06-07 22:02:11,994:INFO:Checking exceptions
2025-06-07 22:02:12,011:INFO:Preloading libraries
2025-06-07 22:02:12,017:INFO:Copying training dataset
2025-06-07 22:02:12,017:INFO:Plot type: auc
2025-06-07 22:02:12,224:INFO:Fitting Model
2025-06-07 22:02:12,224:WARNING:C:\env\ml\Lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names
  warnings.warn(

2025-06-07 22:02:12,224:INFO:Scoring test/hold-out set
2025-06-07 22:02:12,270:INFO:Saving 'C:\Users\JOSECA~1\AppData\Local\Temp\tmpir97p934\AUC.png'
2025-06-07 22:02:12,374:INFO:Visual Rendered Successfully
2025-06-07 22:02:12,478:INFO:plot_model() successfully completed......................................
2025-06-07 22:02:12,482:INFO:Initializing plot_model()
2025-06-07 22:02:12,482:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000235C5235D10>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=131, verbose=0,
                       warm_start=False), plot=confusion_matrix, scale=1, save=C:\Users\JOSECA~1\AppData\Local\Temp\tmpir97p934, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=False, display=None, display_format=None)
2025-06-07 22:02:12,482:INFO:Checking exceptions
2025-06-07 22:02:12,501:INFO:Preloading libraries
2025-06-07 22:02:12,507:INFO:Copying training dataset
2025-06-07 22:02:12,507:INFO:Plot type: confusion_matrix
2025-06-07 22:02:12,726:INFO:Fitting Model
2025-06-07 22:02:12,726:WARNING:C:\env\ml\Lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names
  warnings.warn(

2025-06-07 22:02:12,726:INFO:Scoring test/hold-out set
2025-06-07 22:02:12,771:INFO:Saving 'C:\Users\JOSECA~1\AppData\Local\Temp\tmpir97p934\Confusion Matrix.png'
2025-06-07 22:02:12,827:INFO:Visual Rendered Successfully
2025-06-07 22:02:12,936:INFO:plot_model() successfully completed......................................
2025-06-07 22:02:12,941:INFO:Initializing plot_model()
2025-06-07 22:02:12,941:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000235C5235D10>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=131, verbose=0,
                       warm_start=False), plot=feature, scale=1, save=C:\Users\JOSECA~1\AppData\Local\Temp\tmpir97p934, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=False, display=None, display_format=None)
2025-06-07 22:02:12,941:INFO:Checking exceptions
2025-06-07 22:02:12,959:INFO:Preloading libraries
2025-06-07 22:02:12,965:INFO:Copying training dataset
2025-06-07 22:02:12,965:INFO:Plot type: feature
2025-06-07 22:02:12,966:WARNING:No coef_ found. Trying feature_importances_
2025-06-07 22:02:13,106:INFO:Saving 'C:\Users\JOSECA~1\AppData\Local\Temp\tmpir97p934\Feature Importance.png'
2025-06-07 22:02:13,193:INFO:Visual Rendered Successfully
2025-06-07 22:02:13,287:INFO:plot_model() successfully completed......................................
2025-06-07 22:02:13,290:INFO:SubProcess plot_model() end ==================================
2025-06-07 22:02:13,477:INFO:_master_model_container: 16
2025-06-07 22:02:13,478:INFO:_display_container: 3
2025-06-07 22:02:13,478:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=131, verbose=0,
                       warm_start=False)
2025-06-07 22:02:13,478:INFO:tune_model() successfully completed......................................
2025-06-07 22:02:13,586:INFO:Initializing save_model()
2025-06-07 22:02:13,586:INFO:save_model(model=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=131, verbose=0,
                       warm_start=False), model_name=modelo_responde_oferta_mlflow, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\JOSECA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'ingreso_mensual',
                                             'usa_app', 'usa_web',
                                             'satisfaccion', 'num_productos',
                                             'reclamos_ult_6m',
                                             'tasa_credito'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_feature...
                                                                         'data_type': dtype('O'),
                                                                         'mapping': F      0
M      1
NaN   -1
dtype: int64}],
                                                               return_df=True,
                                                               verbose=0))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['nivel_educacion', 'region'],
                                    transformer=OneHotEncoder(cols=['nivel_educacion',
                                                                    'region'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-06-07 22:02:13,586:INFO:Adding model into prep_pipe
2025-06-07 22:02:13,617:INFO:modelo_responde_oferta_mlflow.pkl saved in current working directory
2025-06-07 22:02:13,627:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'ingreso_mensual',
                                             'usa_app', 'usa_web',
                                             'satisfaccion', 'num_productos',
                                             'reclamos_ult_6m',
                                             'tasa_credito'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean')...
                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,
                                        class_weight=None, criterion='gini',
                                        max_depth=None, max_features='sqrt',
                                        max_leaf_nodes=None, max_samples=None,
                                        min_impurity_decrease=0.0,
                                        min_samples_leaf=1, min_samples_split=2,
                                        min_weight_fraction_leaf=0.0,
                                        monotonic_cst=None, n_estimators=100,
                                        n_jobs=-1, oob_score=False,
                                        random_state=131, verbose=0,
                                        warm_start=False))],
         verbose=False)
2025-06-07 22:02:13,627:INFO:save_model() successfully completed......................................
2025-06-07 22:07:41,043:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-07 22:07:41,044:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-07 22:07:41,044:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-07 22:07:41,044:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-07 22:07:42,764:INFO:Initializing load_model()
2025-06-07 22:07:42,764:INFO:load_model(model_name=modelo_responde_oferta_mlflow, platform=None, authentication=None, verbose=True)
2025-06-07 22:16:01,082:INFO:Initializing predict_model()
2025-06-07 22:16:01,082:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017890614890>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['edad', 'ingreso_mensual',
                                             'usa_app', 'usa_web',
                                             'satisfaccion', 'num_productos',
                                             'reclamos_ult_6m',
                                             'tasa_credito'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['genero', 'nivel_educacion',
                                             'region'],
                                    transformer=SimpleImputer(st...
                                                               handle_missing='return_nan',
                                                               mapping=[{'col': 'genero',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': F      0
M      1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['nivel_educacion', 'region'],
                                    transformer=OneHotEncoder(cols=['nivel_educacion',
                                                                    'region'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('trained_model',
                 RandomForestClassifier(n_jobs=-1, random_state=131))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000178FEE507C0>)
2025-06-07 22:16:01,082:INFO:Checking exceptions
2025-06-07 22:16:01,082:INFO:Preloading libraries
2025-06-07 22:16:01,082:INFO:Set up data.
2025-06-07 22:16:01,090:INFO:Set up index.
2025-06-07 22:22:44,818:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-07 22:22:44,818:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-07 22:22:44,818:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-07 22:22:44,818:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-07 22:22:45,793:INFO:PyCaret ClassificationExperiment
2025-06-07 22:22:45,793:INFO:Logging name: clf-default-name
2025-06-07 22:22:45,793:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-06-07 22:22:45,793:INFO:version 3.3.2
2025-06-07 22:22:45,793:INFO:Initializing setup()
2025-06-07 22:22:45,793:INFO:self.USI: ef3d
2025-06-07 22:22:45,793:INFO:self._variable_keys: {'fold_groups_param', 'data', 'fold_generator', 'log_plots_param', 'fold_shuffle_param', 'n_jobs_param', 'y_test', 'is_multiclass', 'USI', 'X_test', 'idx', 'logging_param', 'exp_name_log', 'memory', '_available_plots', 'fix_imbalance', 'y', 'y_train', 'gpu_param', 'seed', 'html_param', 'target_param', 'X', 'X_train', '_ml_usecase', 'gpu_n_jobs_param', 'pipeline', 'exp_id'}
2025-06-07 22:22:45,793:INFO:Checking environment
2025-06-07 22:22:45,793:INFO:python_version: 3.11.0
2025-06-07 22:22:45,793:INFO:python_build: ('main', 'Oct 24 2022 18:26:48')
2025-06-07 22:22:45,793:INFO:machine: AMD64
2025-06-07 22:22:45,817:INFO:platform: Windows-10-10.0.26100-SP0
2025-06-07 22:22:45,838:INFO:Memory: svmem(total=16438312960, available=2116366336, percent=87.1, used=14321946624, free=2116366336)
2025-06-07 22:22:45,839:INFO:Physical Core: 8
2025-06-07 22:22:45,839:INFO:Logical Core: 16
2025-06-07 22:22:45,839:INFO:Checking libraries
2025-06-07 22:22:45,839:INFO:System:
2025-06-07 22:22:45,839:INFO:    python: 3.11.0 (main, Oct 24 2022, 18:26:48) [MSC v.1933 64 bit (AMD64)]
2025-06-07 22:22:45,839:INFO:executable: C:\env\ml\Scripts\python.exe
2025-06-07 22:22:45,839:INFO:   machine: Windows-10-10.0.26100-SP0
2025-06-07 22:22:45,839:INFO:PyCaret required dependencies:
2025-06-07 22:22:45,901:INFO:                 pip: 22.3
2025-06-07 22:22:45,901:INFO:          setuptools: 65.5.0
2025-06-07 22:22:45,901:INFO:             pycaret: 3.3.2
2025-06-07 22:22:45,901:INFO:             IPython: 9.2.0
2025-06-07 22:22:45,901:INFO:          ipywidgets: 8.1.7
2025-06-07 22:22:45,901:INFO:                tqdm: 4.67.1
2025-06-07 22:22:45,901:INFO:               numpy: 1.26.4
2025-06-07 22:22:45,901:INFO:              pandas: 2.1.4
2025-06-07 22:22:45,901:INFO:              jinja2: 3.1.6
2025-06-07 22:22:45,901:INFO:               scipy: 1.11.4
2025-06-07 22:22:45,901:INFO:              joblib: 1.3.2
2025-06-07 22:22:45,901:INFO:             sklearn: 1.4.2
2025-06-07 22:22:45,901:INFO:                pyod: 2.0.5
2025-06-07 22:22:45,902:INFO:            imblearn: 0.13.0
2025-06-07 22:22:45,902:INFO:   category_encoders: 2.7.0
2025-06-07 22:22:45,902:INFO:            lightgbm: 4.6.0
2025-06-07 22:22:45,902:INFO:               numba: 0.61.0
2025-06-07 22:22:45,902:INFO:            requests: 2.32.3
2025-06-07 22:22:45,902:INFO:          matplotlib: 3.7.5
2025-06-07 22:22:45,902:INFO:          scikitplot: 0.3.7
2025-06-07 22:22:45,902:INFO:         yellowbrick: 1.5
2025-06-07 22:22:45,902:INFO:              plotly: 5.24.1
2025-06-07 22:22:45,902:INFO:    plotly-resampler: Not installed
2025-06-07 22:22:45,902:INFO:             kaleido: 0.2.1
2025-06-07 22:22:45,902:INFO:           schemdraw: 0.15
2025-06-07 22:22:45,902:INFO:         statsmodels: 0.14.4
2025-06-07 22:22:45,902:INFO:              sktime: 0.26.0
2025-06-07 22:22:45,902:INFO:               tbats: 1.1.3
2025-06-07 22:22:45,902:INFO:            pmdarima: 2.0.4
2025-06-07 22:22:45,902:INFO:              psutil: 7.0.0
2025-06-07 22:22:45,902:INFO:          markupsafe: 3.0.2
2025-06-07 22:22:45,902:INFO:             pickle5: Not installed
2025-06-07 22:22:45,903:INFO:         cloudpickle: 3.1.1
2025-06-07 22:22:45,903:INFO:         deprecation: 2.1.0
2025-06-07 22:22:45,903:INFO:              xxhash: 3.5.0
2025-06-07 22:22:45,903:INFO:           wurlitzer: Not installed
2025-06-07 22:22:45,903:INFO:PyCaret optional dependencies:
2025-06-07 22:22:46,035:INFO:                shap: 0.44.1
2025-06-07 22:22:46,035:INFO:           interpret: 0.6.10
2025-06-07 22:22:46,035:INFO:                umap: 0.5.7
2025-06-07 22:22:46,035:INFO:     ydata_profiling: 4.16.1
2025-06-07 22:22:46,035:INFO:  explainerdashboard: 0.4.8
2025-06-07 22:22:46,035:INFO:             autoviz: Not installed
2025-06-07 22:22:46,035:INFO:           fairlearn: 0.7.0
2025-06-07 22:22:46,035:INFO:          deepchecks: Not installed
2025-06-07 22:22:46,035:INFO:             xgboost: Not installed
2025-06-07 22:22:46,035:INFO:            catboost: Not installed
2025-06-07 22:22:46,035:INFO:              kmodes: Not installed
2025-06-07 22:22:46,035:INFO:             mlxtend: Not installed
2025-06-07 22:22:46,035:INFO:       statsforecast: Not installed
2025-06-07 22:22:46,035:INFO:        tune_sklearn: Not installed
2025-06-07 22:22:46,035:INFO:                 ray: Not installed
2025-06-07 22:22:46,035:INFO:            hyperopt: Not installed
2025-06-07 22:22:46,035:INFO:              optuna: Not installed
2025-06-07 22:22:46,035:INFO:               skopt: Not installed
2025-06-07 22:22:46,035:INFO:              mlflow: 2.22.0
2025-06-07 22:22:46,036:INFO:              gradio: Not installed
2025-06-07 22:22:46,036:INFO:             fastapi: 0.115.12
2025-06-07 22:22:46,036:INFO:             uvicorn: 0.34.2
2025-06-07 22:22:46,036:INFO:              m2cgen: Not installed
2025-06-07 22:22:46,036:INFO:           evidently: Not installed
2025-06-07 22:22:46,036:INFO:               fugue: Not installed
2025-06-07 22:22:46,036:INFO:           streamlit: Not installed
2025-06-07 22:22:46,036:INFO:             prophet: Not installed
2025-06-07 22:22:46,036:INFO:None
2025-06-07 22:22:46,036:INFO:Set up data.
2025-06-07 22:22:46,040:INFO:Set up folding strategy.
2025-06-07 22:22:46,040:INFO:Set up train/test split.
2025-06-07 22:22:46,046:INFO:Set up index.
2025-06-07 22:22:46,047:INFO:Assigning column types.
2025-06-07 22:22:46,049:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-06-07 22:22:46,076:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-07 22:22:46,079:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-06-07 22:22:46,195:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-07 22:22:46,195:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-07 22:22:46,224:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-06-07 22:22:46,224:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-06-07 22:22:46,242:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-07 22:22:46,242:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-07 22:22:46,242:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-06-07 22:22:46,270:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-06-07 22:22:46,288:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-07 22:22:46,288:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-07 22:22:46,317:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-06-07 22:22:46,334:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-07 22:22:46,334:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-07 22:22:46,334:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-06-07 22:22:46,380:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-07 22:22:46,380:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-07 22:22:46,426:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-07 22:22:46,426:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-07 22:22:46,429:INFO:Preparing preprocessing pipeline...
2025-06-07 22:22:46,430:INFO:Set up simple imputation.
2025-06-07 22:22:46,433:INFO:Set up encoding of ordinal features.
2025-06-07 22:22:46,434:INFO:Set up encoding of categorical features.
2025-06-07 22:22:46,498:INFO:Finished creating preprocessing pipeline.
2025-06-07 22:22:46,510:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\JOSECA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['edad', 'ingreso_mensual',
                                             'usa_app', 'usa_web',
                                             'satisfaccion', 'num_productos',
                                             'reclamos_ult_6m',
                                             'tasa_credito'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_feature...
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('rest_encoding',
                 TransformerWrapper(exclude=None, include=['cliente_id'],
                                    transformer=TargetEncoder(cols=['cliente_id'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0)))],
         verbose=False)
2025-06-07 22:22:46,510:INFO:Creating final display dataframe.
2025-06-07 22:22:46,685:INFO:Setup _display_container:                     Description             Value
0                    Session id               131
1                        Target  respondio_oferta
2                   Target type            Binary
3           Original data shape         (500, 13)
4        Transformed data shape         (500, 19)
5   Transformed train set shape         (350, 19)
6    Transformed test set shape         (150, 19)
7              Numeric features                 8
8          Categorical features                 4
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15               Fold Generator   StratifiedKFold
16                  Fold Number                10
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  clf-default-name
21                          USI              ef3d
2025-06-07 22:22:46,733:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-07 22:22:46,733:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-07 22:22:46,779:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-07 22:22:46,780:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-06-07 22:22:46,780:INFO:setup() successfully completed in 1.0s...............
2025-06-07 22:22:46,781:INFO:Initializing compare_models()
2025-06-07 22:22:46,781:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B31AEE0490>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001B31AEE0490>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-06-07 22:22:46,781:INFO:Checking exceptions
2025-06-07 22:22:46,783:INFO:Preparing display monitor
2025-06-07 22:22:46,786:INFO:Initializing Logistic Regression
2025-06-07 22:22:46,786:INFO:Total runtime is 0.0 minutes
2025-06-07 22:22:46,786:INFO:SubProcess create_model() called ==================================
2025-06-07 22:22:46,786:INFO:Initializing create_model()
2025-06-07 22:22:46,786:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B31AEE0490>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B366B94810>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-07 22:22:46,786:INFO:Checking exceptions
2025-06-07 22:22:46,787:INFO:Importing libraries
2025-06-07 22:22:46,787:INFO:Copying training dataset
2025-06-07 22:22:46,789:INFO:Defining folds
2025-06-07 22:22:46,789:INFO:Declaring metric variables
2025-06-07 22:22:46,789:INFO:Importing untrained model
2025-06-07 22:22:46,790:INFO:Logistic Regression Imported successfully
2025-06-07 22:22:46,790:INFO:Starting cross validation
2025-06-07 22:22:46,791:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-07 22:22:52,678:WARNING:C:\env\ml\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-07 22:22:52,686:WARNING:C:\env\ml\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-07 22:22:52,695:WARNING:C:\env\ml\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-07 22:22:52,697:WARNING:C:\env\ml\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-07 22:22:52,698:WARNING:C:\env\ml\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-07 22:22:52,703:WARNING:C:\env\ml\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-07 22:22:52,703:WARNING:C:\env\ml\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-07 22:22:52,703:WARNING:C:\env\ml\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-07 22:22:52,743:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:22:52,751:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:22:52,751:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:22:52,759:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:22:52,760:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:22:52,766:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:22:52,799:WARNING:C:\env\ml\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-07 22:22:52,887:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:22:52,927:WARNING:C:\env\ml\Lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-06-07 22:22:52,965:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:22:52,974:INFO:Calculating mean and std
2025-06-07 22:22:52,975:INFO:Creating metrics dataframe
2025-06-07 22:22:52,978:INFO:Uploading results into container
2025-06-07 22:22:52,978:INFO:Uploading model into container now
2025-06-07 22:22:52,979:INFO:_master_model_container: 1
2025-06-07 22:22:52,979:INFO:_display_container: 2
2025-06-07 22:22:52,979:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=131, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-06-07 22:22:52,979:INFO:create_model() successfully completed......................................
2025-06-07 22:22:53,091:INFO:SubProcess create_model() end ==================================
2025-06-07 22:22:53,091:INFO:Creating metrics dataframe
2025-06-07 22:22:53,093:INFO:Initializing K Neighbors Classifier
2025-06-07 22:22:53,093:INFO:Total runtime is 0.1051148772239685 minutes
2025-06-07 22:22:53,093:INFO:SubProcess create_model() called ==================================
2025-06-07 22:22:53,093:INFO:Initializing create_model()
2025-06-07 22:22:53,093:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B31AEE0490>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B366B94810>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-07 22:22:53,093:INFO:Checking exceptions
2025-06-07 22:22:53,093:INFO:Importing libraries
2025-06-07 22:22:53,093:INFO:Copying training dataset
2025-06-07 22:22:53,096:INFO:Defining folds
2025-06-07 22:22:53,096:INFO:Declaring metric variables
2025-06-07 22:22:53,096:INFO:Importing untrained model
2025-06-07 22:22:53,097:INFO:K Neighbors Classifier Imported successfully
2025-06-07 22:22:53,097:INFO:Starting cross validation
2025-06-07 22:22:53,098:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-07 22:22:56,426:INFO:Calculating mean and std
2025-06-07 22:22:56,427:INFO:Creating metrics dataframe
2025-06-07 22:22:56,430:INFO:Uploading results into container
2025-06-07 22:22:56,431:INFO:Uploading model into container now
2025-06-07 22:22:56,432:INFO:_master_model_container: 2
2025-06-07 22:22:56,432:INFO:_display_container: 2
2025-06-07 22:22:56,433:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-06-07 22:22:56,433:INFO:create_model() successfully completed......................................
2025-06-07 22:22:56,550:INFO:SubProcess create_model() end ==================================
2025-06-07 22:22:56,550:INFO:Creating metrics dataframe
2025-06-07 22:22:56,552:INFO:Initializing Naive Bayes
2025-06-07 22:22:56,552:INFO:Total runtime is 0.16276126305262248 minutes
2025-06-07 22:22:56,552:INFO:SubProcess create_model() called ==================================
2025-06-07 22:22:56,553:INFO:Initializing create_model()
2025-06-07 22:22:56,553:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B31AEE0490>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B366B94810>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-07 22:22:56,553:INFO:Checking exceptions
2025-06-07 22:22:56,553:INFO:Importing libraries
2025-06-07 22:22:56,553:INFO:Copying training dataset
2025-06-07 22:22:56,556:INFO:Defining folds
2025-06-07 22:22:56,556:INFO:Declaring metric variables
2025-06-07 22:22:56,556:INFO:Importing untrained model
2025-06-07 22:22:56,556:INFO:Naive Bayes Imported successfully
2025-06-07 22:22:56,556:INFO:Starting cross validation
2025-06-07 22:22:56,557:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-07 22:22:56,677:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:22:56,679:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:22:56,683:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:22:56,683:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:22:56,684:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:22:56,687:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:22:56,689:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:22:56,691:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:22:56,693:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:22:56,695:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:22:56,703:INFO:Calculating mean and std
2025-06-07 22:22:56,703:INFO:Creating metrics dataframe
2025-06-07 22:22:56,705:INFO:Uploading results into container
2025-06-07 22:22:56,705:INFO:Uploading model into container now
2025-06-07 22:22:56,706:INFO:_master_model_container: 3
2025-06-07 22:22:56,706:INFO:_display_container: 2
2025-06-07 22:22:56,706:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-06-07 22:22:56,706:INFO:create_model() successfully completed......................................
2025-06-07 22:22:56,800:INFO:SubProcess create_model() end ==================================
2025-06-07 22:22:56,800:INFO:Creating metrics dataframe
2025-06-07 22:22:56,803:INFO:Initializing Decision Tree Classifier
2025-06-07 22:22:56,803:INFO:Total runtime is 0.1669573664665222 minutes
2025-06-07 22:22:56,803:INFO:SubProcess create_model() called ==================================
2025-06-07 22:22:56,803:INFO:Initializing create_model()
2025-06-07 22:22:56,803:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B31AEE0490>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B366B94810>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-07 22:22:56,803:INFO:Checking exceptions
2025-06-07 22:22:56,803:INFO:Importing libraries
2025-06-07 22:22:56,803:INFO:Copying training dataset
2025-06-07 22:22:56,807:INFO:Defining folds
2025-06-07 22:22:56,807:INFO:Declaring metric variables
2025-06-07 22:22:56,807:INFO:Importing untrained model
2025-06-07 22:22:56,807:INFO:Decision Tree Classifier Imported successfully
2025-06-07 22:22:56,807:INFO:Starting cross validation
2025-06-07 22:22:56,808:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-07 22:22:56,922:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:22:56,923:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:22:56,924:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:22:56,925:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:22:56,927:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:22:56,927:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:22:56,930:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:22:56,932:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:22:56,932:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:22:56,938:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:22:56,943:INFO:Calculating mean and std
2025-06-07 22:22:56,944:INFO:Creating metrics dataframe
2025-06-07 22:22:56,946:INFO:Uploading results into container
2025-06-07 22:22:56,946:INFO:Uploading model into container now
2025-06-07 22:22:56,946:INFO:_master_model_container: 4
2025-06-07 22:22:56,946:INFO:_display_container: 2
2025-06-07 22:22:56,947:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=131, splitter='best')
2025-06-07 22:22:56,947:INFO:create_model() successfully completed......................................
2025-06-07 22:22:57,041:INFO:SubProcess create_model() end ==================================
2025-06-07 22:22:57,041:INFO:Creating metrics dataframe
2025-06-07 22:22:57,043:INFO:Initializing SVM - Linear Kernel
2025-06-07 22:22:57,043:INFO:Total runtime is 0.1709567864735921 minutes
2025-06-07 22:22:57,043:INFO:SubProcess create_model() called ==================================
2025-06-07 22:22:57,043:INFO:Initializing create_model()
2025-06-07 22:22:57,044:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B31AEE0490>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B366B94810>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-07 22:22:57,044:INFO:Checking exceptions
2025-06-07 22:22:57,044:INFO:Importing libraries
2025-06-07 22:22:57,044:INFO:Copying training dataset
2025-06-07 22:22:57,047:INFO:Defining folds
2025-06-07 22:22:57,047:INFO:Declaring metric variables
2025-06-07 22:22:57,047:INFO:Importing untrained model
2025-06-07 22:22:57,048:INFO:SVM - Linear Kernel Imported successfully
2025-06-07 22:22:57,048:INFO:Starting cross validation
2025-06-07 22:22:57,049:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-07 22:22:57,145:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:22:57,154:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:22:57,164:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:22:57,165:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:22:57,174:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:22:57,185:INFO:Calculating mean and std
2025-06-07 22:22:57,185:INFO:Creating metrics dataframe
2025-06-07 22:22:57,187:INFO:Uploading results into container
2025-06-07 22:22:57,187:INFO:Uploading model into container now
2025-06-07 22:22:57,188:INFO:_master_model_container: 5
2025-06-07 22:22:57,188:INFO:_display_container: 2
2025-06-07 22:22:57,188:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=131, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-06-07 22:22:57,188:INFO:create_model() successfully completed......................................
2025-06-07 22:22:57,286:INFO:SubProcess create_model() end ==================================
2025-06-07 22:22:57,286:INFO:Creating metrics dataframe
2025-06-07 22:22:57,288:INFO:Initializing Ridge Classifier
2025-06-07 22:22:57,288:INFO:Total runtime is 0.1750389536221822 minutes
2025-06-07 22:22:57,288:INFO:SubProcess create_model() called ==================================
2025-06-07 22:22:57,288:INFO:Initializing create_model()
2025-06-07 22:22:57,288:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B31AEE0490>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B366B94810>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-07 22:22:57,288:INFO:Checking exceptions
2025-06-07 22:22:57,288:INFO:Importing libraries
2025-06-07 22:22:57,288:INFO:Copying training dataset
2025-06-07 22:22:57,291:INFO:Defining folds
2025-06-07 22:22:57,291:INFO:Declaring metric variables
2025-06-07 22:22:57,291:INFO:Importing untrained model
2025-06-07 22:22:57,292:INFO:Ridge Classifier Imported successfully
2025-06-07 22:22:57,292:INFO:Starting cross validation
2025-06-07 22:22:57,293:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-07 22:22:57,401:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:22:57,401:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:22:57,401:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:22:57,405:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:22:57,405:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:22:57,406:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:22:57,411:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:22:57,411:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:22:57,416:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:22:57,420:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:22:57,429:INFO:Calculating mean and std
2025-06-07 22:22:57,430:INFO:Creating metrics dataframe
2025-06-07 22:22:57,432:INFO:Uploading results into container
2025-06-07 22:22:57,433:INFO:Uploading model into container now
2025-06-07 22:22:57,433:INFO:_master_model_container: 6
2025-06-07 22:22:57,433:INFO:_display_container: 2
2025-06-07 22:22:57,433:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=131, solver='auto',
                tol=0.0001)
2025-06-07 22:22:57,433:INFO:create_model() successfully completed......................................
2025-06-07 22:22:57,530:INFO:SubProcess create_model() end ==================================
2025-06-07 22:22:57,530:INFO:Creating metrics dataframe
2025-06-07 22:22:57,532:INFO:Initializing Random Forest Classifier
2025-06-07 22:22:57,533:INFO:Total runtime is 0.1791236639022827 minutes
2025-06-07 22:22:57,533:INFO:SubProcess create_model() called ==================================
2025-06-07 22:22:57,533:INFO:Initializing create_model()
2025-06-07 22:22:57,533:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B31AEE0490>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B366B94810>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-07 22:22:57,533:INFO:Checking exceptions
2025-06-07 22:22:57,533:INFO:Importing libraries
2025-06-07 22:22:57,533:INFO:Copying training dataset
2025-06-07 22:22:57,537:INFO:Defining folds
2025-06-07 22:22:57,537:INFO:Declaring metric variables
2025-06-07 22:22:57,537:INFO:Importing untrained model
2025-06-07 22:22:57,538:INFO:Random Forest Classifier Imported successfully
2025-06-07 22:22:57,538:INFO:Starting cross validation
2025-06-07 22:22:57,539:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-07 22:22:57,970:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:22:57,975:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:22:57,982:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:22:57,983:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:22:57,983:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:22:57,984:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:22:57,984:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:22:57,984:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:22:57,985:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:22:57,986:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:22:58,001:INFO:Calculating mean and std
2025-06-07 22:22:58,002:INFO:Creating metrics dataframe
2025-06-07 22:22:58,003:INFO:Uploading results into container
2025-06-07 22:22:58,004:INFO:Uploading model into container now
2025-06-07 22:22:58,004:INFO:_master_model_container: 7
2025-06-07 22:22:58,004:INFO:_display_container: 2
2025-06-07 22:22:58,004:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=131, verbose=0,
                       warm_start=False)
2025-06-07 22:22:58,004:INFO:create_model() successfully completed......................................
2025-06-07 22:22:58,098:INFO:SubProcess create_model() end ==================================
2025-06-07 22:22:58,098:INFO:Creating metrics dataframe
2025-06-07 22:22:58,100:INFO:Initializing Quadratic Discriminant Analysis
2025-06-07 22:22:58,100:INFO:Total runtime is 0.18856364885965982 minutes
2025-06-07 22:22:58,100:INFO:SubProcess create_model() called ==================================
2025-06-07 22:22:58,100:INFO:Initializing create_model()
2025-06-07 22:22:58,101:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B31AEE0490>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B366B94810>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-07 22:22:58,101:INFO:Checking exceptions
2025-06-07 22:22:58,101:INFO:Importing libraries
2025-06-07 22:22:58,101:INFO:Copying training dataset
2025-06-07 22:22:58,103:INFO:Defining folds
2025-06-07 22:22:58,104:INFO:Declaring metric variables
2025-06-07 22:22:58,104:INFO:Importing untrained model
2025-06-07 22:22:58,104:INFO:Quadratic Discriminant Analysis Imported successfully
2025-06-07 22:22:58,104:INFO:Starting cross validation
2025-06-07 22:22:58,106:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-07 22:22:58,181:WARNING:C:\env\ml\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-06-07 22:22:58,181:WARNING:C:\env\ml\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-06-07 22:22:58,181:WARNING:C:\env\ml\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-06-07 22:22:58,182:WARNING:C:\env\ml\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-06-07 22:22:58,184:WARNING:C:\env\ml\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-06-07 22:22:58,184:WARNING:C:\env\ml\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-06-07 22:22:58,193:WARNING:C:\env\ml\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-06-07 22:22:58,200:WARNING:C:\env\ml\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-06-07 22:22:58,202:WARNING:C:\env\ml\Lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-06-07 22:22:58,210:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:22:58,211:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:22:58,215:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:22:58,215:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:22:58,222:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:22:58,223:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:22:58,228:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:22:58,229:WARNING:C:\env\ml\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-06-07 22:22:58,229:WARNING:C:\env\ml\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-06-07 22:22:58,229:WARNING:C:\env\ml\Lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-06-07 22:22:58,230:WARNING:C:\env\ml\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-06-07 22:22:58,231:WARNING:C:\env\ml\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-06-07 22:22:58,231:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:22:58,231:WARNING:C:\env\ml\Lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-06-07 22:22:58,231:WARNING:C:\env\ml\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-06-07 22:22:58,231:WARNING:C:\env\ml\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-06-07 22:22:58,232:WARNING:C:\env\ml\Lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-06-07 22:22:58,232:WARNING:C:\env\ml\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-06-07 22:22:58,232:WARNING:C:\env\ml\Lib\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2025-06-07 22:22:58,232:WARNING:C:\env\ml\Lib\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2025-06-07 22:22:58,282:WARNING:C:\env\ml\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\env\ml\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\env\ml\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\env\ml\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\env\ml\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\env\ml\Lib\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\env\ml\Lib\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "C:\env\ml\Lib\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "C:\env\ml\Lib\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2025-06-07 22:22:58,294:INFO:Calculating mean and std
2025-06-07 22:22:58,294:INFO:Creating metrics dataframe
2025-06-07 22:22:58,295:INFO:Uploading results into container
2025-06-07 22:22:58,296:INFO:Uploading model into container now
2025-06-07 22:22:58,296:INFO:_master_model_container: 8
2025-06-07 22:22:58,296:INFO:_display_container: 2
2025-06-07 22:22:58,296:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-06-07 22:22:58,296:INFO:create_model() successfully completed......................................
2025-06-07 22:22:58,391:INFO:SubProcess create_model() end ==================================
2025-06-07 22:22:58,391:INFO:Creating metrics dataframe
2025-06-07 22:22:58,393:INFO:Initializing Ada Boost Classifier
2025-06-07 22:22:58,393:INFO:Total runtime is 0.19345217545827229 minutes
2025-06-07 22:22:58,393:INFO:SubProcess create_model() called ==================================
2025-06-07 22:22:58,393:INFO:Initializing create_model()
2025-06-07 22:22:58,393:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B31AEE0490>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B366B94810>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-07 22:22:58,393:INFO:Checking exceptions
2025-06-07 22:22:58,393:INFO:Importing libraries
2025-06-07 22:22:58,393:INFO:Copying training dataset
2025-06-07 22:22:58,396:INFO:Defining folds
2025-06-07 22:22:58,396:INFO:Declaring metric variables
2025-06-07 22:22:58,397:INFO:Importing untrained model
2025-06-07 22:22:58,397:INFO:Ada Boost Classifier Imported successfully
2025-06-07 22:22:58,397:INFO:Starting cross validation
2025-06-07 22:22:58,398:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-07 22:22:58,466:WARNING:C:\env\ml\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-06-07 22:22:58,467:WARNING:C:\env\ml\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-06-07 22:22:58,468:WARNING:C:\env\ml\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-06-07 22:22:58,473:WARNING:C:\env\ml\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-06-07 22:22:58,473:WARNING:C:\env\ml\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-06-07 22:22:58,480:WARNING:C:\env\ml\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-06-07 22:22:58,482:WARNING:C:\env\ml\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-06-07 22:22:58,489:WARNING:C:\env\ml\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-06-07 22:22:58,490:WARNING:C:\env\ml\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-06-07 22:22:58,490:WARNING:C:\env\ml\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-06-07 22:22:58,498:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:22:58,500:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:22:58,512:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:22:58,513:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:22:58,514:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:22:58,516:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:22:58,522:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:22:58,522:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:22:58,522:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:22:58,535:INFO:Calculating mean and std
2025-06-07 22:22:58,535:INFO:Creating metrics dataframe
2025-06-07 22:22:58,537:INFO:Uploading results into container
2025-06-07 22:22:58,537:INFO:Uploading model into container now
2025-06-07 22:22:58,537:INFO:_master_model_container: 9
2025-06-07 22:22:58,538:INFO:_display_container: 2
2025-06-07 22:22:58,538:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=131)
2025-06-07 22:22:58,538:INFO:create_model() successfully completed......................................
2025-06-07 22:22:58,637:INFO:SubProcess create_model() end ==================================
2025-06-07 22:22:58,637:INFO:Creating metrics dataframe
2025-06-07 22:22:58,640:INFO:Initializing Gradient Boosting Classifier
2025-06-07 22:22:58,640:INFO:Total runtime is 0.1975635210673014 minutes
2025-06-07 22:22:58,640:INFO:SubProcess create_model() called ==================================
2025-06-07 22:22:58,640:INFO:Initializing create_model()
2025-06-07 22:22:58,640:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B31AEE0490>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B366B94810>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-07 22:22:58,640:INFO:Checking exceptions
2025-06-07 22:22:58,640:INFO:Importing libraries
2025-06-07 22:22:58,641:INFO:Copying training dataset
2025-06-07 22:22:58,643:INFO:Defining folds
2025-06-07 22:22:58,643:INFO:Declaring metric variables
2025-06-07 22:22:58,644:INFO:Importing untrained model
2025-06-07 22:22:58,644:INFO:Gradient Boosting Classifier Imported successfully
2025-06-07 22:22:58,644:INFO:Starting cross validation
2025-06-07 22:22:58,645:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-07 22:22:58,821:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:22:58,826:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:22:58,833:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:22:58,835:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:22:58,836:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:22:58,839:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:22:58,842:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:22:58,842:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:22:58,842:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:22:58,849:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:22:58,855:INFO:Calculating mean and std
2025-06-07 22:22:58,855:INFO:Creating metrics dataframe
2025-06-07 22:22:58,857:INFO:Uploading results into container
2025-06-07 22:22:58,858:INFO:Uploading model into container now
2025-06-07 22:22:58,858:INFO:_master_model_container: 10
2025-06-07 22:22:58,858:INFO:_display_container: 2
2025-06-07 22:22:58,858:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=131, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-06-07 22:22:58,858:INFO:create_model() successfully completed......................................
2025-06-07 22:22:58,960:INFO:SubProcess create_model() end ==================================
2025-06-07 22:22:58,960:INFO:Creating metrics dataframe
2025-06-07 22:22:58,962:INFO:Initializing Linear Discriminant Analysis
2025-06-07 22:22:58,962:INFO:Total runtime is 0.2029290199279785 minutes
2025-06-07 22:22:58,962:INFO:SubProcess create_model() called ==================================
2025-06-07 22:22:58,962:INFO:Initializing create_model()
2025-06-07 22:22:58,962:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B31AEE0490>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B366B94810>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-07 22:22:58,962:INFO:Checking exceptions
2025-06-07 22:22:58,962:INFO:Importing libraries
2025-06-07 22:22:58,962:INFO:Copying training dataset
2025-06-07 22:22:58,965:INFO:Defining folds
2025-06-07 22:22:58,966:INFO:Declaring metric variables
2025-06-07 22:22:58,966:INFO:Importing untrained model
2025-06-07 22:22:58,966:INFO:Linear Discriminant Analysis Imported successfully
2025-06-07 22:22:58,966:INFO:Starting cross validation
2025-06-07 22:22:58,968:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-07 22:22:59,091:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:22:59,094:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:22:59,098:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:22:59,098:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:22:59,103:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:22:59,103:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:22:59,106:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:22:59,107:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:22:59,110:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:22:59,113:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:22:59,122:INFO:Calculating mean and std
2025-06-07 22:22:59,123:INFO:Creating metrics dataframe
2025-06-07 22:22:59,125:INFO:Uploading results into container
2025-06-07 22:22:59,125:INFO:Uploading model into container now
2025-06-07 22:22:59,125:INFO:_master_model_container: 11
2025-06-07 22:22:59,125:INFO:_display_container: 2
2025-06-07 22:22:59,126:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-06-07 22:22:59,126:INFO:create_model() successfully completed......................................
2025-06-07 22:22:59,227:INFO:SubProcess create_model() end ==================================
2025-06-07 22:22:59,227:INFO:Creating metrics dataframe
2025-06-07 22:22:59,228:INFO:Initializing Extra Trees Classifier
2025-06-07 22:22:59,229:INFO:Total runtime is 0.20738498369852698 minutes
2025-06-07 22:22:59,229:INFO:SubProcess create_model() called ==================================
2025-06-07 22:22:59,229:INFO:Initializing create_model()
2025-06-07 22:22:59,229:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B31AEE0490>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B366B94810>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-07 22:22:59,229:INFO:Checking exceptions
2025-06-07 22:22:59,229:INFO:Importing libraries
2025-06-07 22:22:59,229:INFO:Copying training dataset
2025-06-07 22:22:59,232:INFO:Defining folds
2025-06-07 22:22:59,232:INFO:Declaring metric variables
2025-06-07 22:22:59,232:INFO:Importing untrained model
2025-06-07 22:22:59,233:INFO:Extra Trees Classifier Imported successfully
2025-06-07 22:22:59,233:INFO:Starting cross validation
2025-06-07 22:22:59,234:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-07 22:22:59,537:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:22:59,539:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:22:59,541:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:22:59,541:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:22:59,542:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:22:59,544:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:22:59,550:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:22:59,552:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:22:59,557:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:22:59,561:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:22:59,568:INFO:Calculating mean and std
2025-06-07 22:22:59,569:INFO:Creating metrics dataframe
2025-06-07 22:22:59,570:INFO:Uploading results into container
2025-06-07 22:22:59,570:INFO:Uploading model into container now
2025-06-07 22:22:59,570:INFO:_master_model_container: 12
2025-06-07 22:22:59,571:INFO:_display_container: 2
2025-06-07 22:22:59,571:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=131, verbose=0,
                     warm_start=False)
2025-06-07 22:22:59,571:INFO:create_model() successfully completed......................................
2025-06-07 22:22:59,667:INFO:SubProcess create_model() end ==================================
2025-06-07 22:22:59,667:INFO:Creating metrics dataframe
2025-06-07 22:22:59,669:INFO:Initializing Light Gradient Boosting Machine
2025-06-07 22:22:59,669:INFO:Total runtime is 0.21471533775329585 minutes
2025-06-07 22:22:59,669:INFO:SubProcess create_model() called ==================================
2025-06-07 22:22:59,669:INFO:Initializing create_model()
2025-06-07 22:22:59,669:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B31AEE0490>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B366B94810>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-07 22:22:59,669:INFO:Checking exceptions
2025-06-07 22:22:59,669:INFO:Importing libraries
2025-06-07 22:22:59,669:INFO:Copying training dataset
2025-06-07 22:22:59,672:INFO:Defining folds
2025-06-07 22:22:59,672:INFO:Declaring metric variables
2025-06-07 22:22:59,672:INFO:Importing untrained model
2025-06-07 22:22:59,673:INFO:Light Gradient Boosting Machine Imported successfully
2025-06-07 22:22:59,673:INFO:Starting cross validation
2025-06-07 22:22:59,674:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-07 22:23:00,111:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:23:00,164:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:23:00,179:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:23:00,194:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:23:00,218:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:23:00,252:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:23:00,264:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:23:00,277:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:23:00,312:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:23:00,324:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:23:00,332:INFO:Calculating mean and std
2025-06-07 22:23:00,333:INFO:Creating metrics dataframe
2025-06-07 22:23:00,335:INFO:Uploading results into container
2025-06-07 22:23:00,335:INFO:Uploading model into container now
2025-06-07 22:23:00,335:INFO:_master_model_container: 13
2025-06-07 22:23:00,335:INFO:_display_container: 2
2025-06-07 22:23:00,336:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=131, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-06-07 22:23:00,336:INFO:create_model() successfully completed......................................
2025-06-07 22:23:00,453:INFO:SubProcess create_model() end ==================================
2025-06-07 22:23:00,453:INFO:Creating metrics dataframe
2025-06-07 22:23:00,454:INFO:Initializing Dummy Classifier
2025-06-07 22:23:00,454:INFO:Total runtime is 0.2278029322624206 minutes
2025-06-07 22:23:00,455:INFO:SubProcess create_model() called ==================================
2025-06-07 22:23:00,455:INFO:Initializing create_model()
2025-06-07 22:23:00,455:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B31AEE0490>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B366B94810>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-07 22:23:00,455:INFO:Checking exceptions
2025-06-07 22:23:00,455:INFO:Importing libraries
2025-06-07 22:23:00,455:INFO:Copying training dataset
2025-06-07 22:23:00,458:INFO:Defining folds
2025-06-07 22:23:00,458:INFO:Declaring metric variables
2025-06-07 22:23:00,458:INFO:Importing untrained model
2025-06-07 22:23:00,458:INFO:Dummy Classifier Imported successfully
2025-06-07 22:23:00,459:INFO:Starting cross validation
2025-06-07 22:23:00,460:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-06-07 22:23:00,566:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:23:00,568:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:23:00,576:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:23:00,576:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:23:00,576:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:23:00,579:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:23:00,579:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:23:00,583:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:23:00,586:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:23:00,586:WARNING:C:\env\ml\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-06-07 22:23:00,595:INFO:Calculating mean and std
2025-06-07 22:23:00,597:INFO:Creating metrics dataframe
2025-06-07 22:23:00,598:INFO:Uploading results into container
2025-06-07 22:23:00,599:INFO:Uploading model into container now
2025-06-07 22:23:00,599:INFO:_master_model_container: 14
2025-06-07 22:23:00,599:INFO:_display_container: 2
2025-06-07 22:23:00,599:INFO:DummyClassifier(constant=None, random_state=131, strategy='prior')
2025-06-07 22:23:00,599:INFO:create_model() successfully completed......................................
2025-06-07 22:23:00,696:INFO:SubProcess create_model() end ==================================
2025-06-07 22:23:00,696:INFO:Creating metrics dataframe
2025-06-07 22:23:00,700:INFO:Initializing create_model()
2025-06-07 22:23:00,700:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B31AEE0490>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-06-07 22:23:00,700:INFO:Checking exceptions
2025-06-07 22:23:00,701:INFO:Importing libraries
2025-06-07 22:23:00,701:INFO:Copying training dataset
2025-06-07 22:23:00,704:INFO:Defining folds
2025-06-07 22:23:00,704:INFO:Declaring metric variables
2025-06-07 22:23:00,704:INFO:Importing untrained model
2025-06-07 22:23:00,705:INFO:Declaring custom model
2025-06-07 22:23:00,705:INFO:Naive Bayes Imported successfully
2025-06-07 22:23:00,706:INFO:Cross validation set to False
2025-06-07 22:23:00,706:INFO:Fitting Model
2025-06-07 22:23:00,746:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-06-07 22:23:00,746:INFO:create_model() successfully completed......................................
2025-06-07 22:23:00,848:INFO:_master_model_container: 14
2025-06-07 22:23:00,848:INFO:_display_container: 2
2025-06-07 22:23:00,848:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-06-07 22:23:00,848:INFO:compare_models() successfully completed......................................
2025-06-07 22:23:00,849:INFO:Initializing evaluate_model()
2025-06-07 22:23:00,849:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B31AEE0490>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-06-07 22:23:00,919:INFO:Initializing plot_model()
2025-06-07 22:23:00,919:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B31AEE0490>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), plot=pipeline, scale=1, save=False, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-06-07 22:23:00,919:INFO:Checking exceptions
2025-06-07 22:23:00,920:INFO:Preloading libraries
2025-06-07 22:23:00,920:INFO:Copying training dataset
2025-06-07 22:23:00,920:INFO:Plot type: pipeline
